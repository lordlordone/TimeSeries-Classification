{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb-hUfc0JK_5"
      },
      "source": [
        "**Room Occupancy Prediction using Deep Neural Networks**\n",
        "\n",
        "\n",
        "In this project, we explore a machine learning approach to predict room occupancy using a dataset that includes features such as ```Temperature```, ```Humidity```, ```Light```, and ```Carbon Dioxide (CO2)``` levels. The target variable is binary, indicating the presence ```1``` or absence ```0``` of room occupancy.\n",
        "\n",
        "**Dataset Overview**\n",
        "\n",
        "The dataset provides the following features:\n",
        "\n",
        "* Temperature\n",
        "* Humidity\n",
        "* Light\n",
        "* Carbon Dioxide (CO2)\n",
        "\n",
        "The target variable is:\n",
        "\n",
        "* 1 - Indicates room occupancy.\n",
        "* 0 - Indicates no room occupancy.\n",
        "\n",
        "The dataset offers a unique opportunity to explore binary classification through various exploratory data analysis (EDA) techniques and predictive modeling.\n",
        "\n",
        "**Project Highlights**\n",
        "\n",
        "In this notebook, we focus on leveraging **Deep Neural Networks (DNN)**, specifically:\n",
        "\n",
        "* Long Short-Term Memory (LSTM) networks to capture temporal dependencies in the data.\n",
        "* Deep Feedforward Neural Networks (DFNN) for feature representation and classification.\n",
        "\n",
        "**Key Achievements:**\n",
        "\n",
        "Achieved accuracy between 95% and 100% in predicting room occupancy.\n",
        "High F1 scores for both classes, demonstrating balanced performance.\n",
        "\n",
        "Reduced the number of variables used compared to the original dataset, highlighting the efficiency of the modeling approach.\n",
        "\n",
        "\n",
        "\n",
        "> **Dataset link:** https://www.kaggle.com/datasets/sachinsharma1123/room-occupancy/data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY64LuPHJL_3"
      },
      "source": [
        "# Modules installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxY7OPqM_Szj",
        "outputId": "469c6ae7-28bc-41d1-fccb-bb219d5046a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyts in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from pyts) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from pyts) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyts) (1.6.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from pyts) (1.4.2)\n",
            "Requirement already satisfied: numba>=0.55.2 in /usr/local/lib/python3.11/dist-packages (from pyts) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.55.2->pyts) (0.43.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->pyts) (3.5.0)\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyts\n",
        "!pip install keras-tuner\n",
        "#!pip install keras-nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFy3Zi6aAjGJ"
      },
      "source": [
        "# Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jAznPfB9AigQ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from scipy.stats import norm\n",
        "from pyts.approximation import SymbolicAggregateApproximation\n",
        "#from pyts.approximation import DiscreteFourierTransform\n",
        "#from pyts.approximation import PiecewiseAggregateApproximation\n",
        "from scipy.interpolate import interp1d\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import keras\n",
        "from keras.metrics import AUC\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import AveragePooling1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.layers import Average\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Add\n",
        "from keras.layers import Multiply\n",
        "from keras.layers import LayerNormalization\n",
        "#from keras_nlp.layers import TransformerEncoder\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from keras.layers import Input\n",
        "import keras_tuner as kt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atEFzi6TAr7b"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg78ho6ASXiK"
      },
      "source": [
        "The ```Preprocessing``` class processes both training and test set by deleting 'Unnamed: 0' column and adding the hour column derived from the 'Date' column.\n",
        "\n",
        "Furthermore, with ```.get_info()``` it is  possible to check information on both sets and it has a method to plot specific features with  ```.plot_ts(column, train)```.\n",
        "\n",
        "It also possible to get these preprocessed sets with the methods  ``` .get_train() ``` and  ``` .get_test() ```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NTzmhM6UAtTr"
      },
      "outputs": [],
      "source": [
        "class Preprocessing:\n",
        "\n",
        "  # the building methods allows to import datasets. Then it will drop unnecessary default column\n",
        "  # and adding the hours feature through the date column.\n",
        "  def __init__(self, path, filename_train, filename_test):\n",
        "\n",
        "    # preparing working directory\n",
        "    drive.mount('/content/drive')\n",
        "    os.chdir(path)\n",
        "\n",
        "    # loading train and test sets\n",
        "    self.df_train = pd.read_csv(path + filename_train)\n",
        "    self.df_test = pd.read_csv(path + filename_test)\n",
        "\n",
        "    # deleting \"unnamed\" column\n",
        "    self.df_train.drop('Unnamed: 0', axis = 1, inplace = True)\n",
        "    self.df_test.drop('Unnamed: 0', axis = 1, inplace = True)\n",
        "\n",
        "    # adding hour feature\n",
        "    self.df_train['date'] = pd.to_datetime(self.df_train['date'])\n",
        "    self.df_test['date'] = pd.to_datetime(self.df_test['date'])\n",
        "\n",
        "    self.df_train['hour'] = self.df_train['date'].dt.hour\n",
        "    self.df_test['hour'] = self.df_test['date'].dt.hour\n",
        "\n",
        "\n",
        "  def get_info(self):\n",
        "    print('--------------------- Train ---------------------')\n",
        "    print(self.df_train.info())\n",
        "    print('------------------------ Test --------------------')\n",
        "    print(self.df_test.info())\n",
        "\n",
        "\n",
        "  def plot_ts(self, col, train = True):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    if (train == True):\n",
        "      plt.plot(self.df_train[col], label=col)\n",
        "    elif (train == False):\n",
        "      plt.plot(self.df_test[col], label=col)\n",
        "    else:\n",
        "      return 'define as a parameter if \\'train\\' or \\'test\\''\n",
        "\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel(col)\n",
        "    plt.title(f'{col} Time Series Plot')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  def get_train(self):\n",
        "    return self.df_train\n",
        "\n",
        "\n",
        "  def get_test(self):\n",
        "    return self.df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN6jopW3U4gC"
      },
      "source": [
        "The main porpouse of ```Shrinker``` is to prepare the data in a format suitable for the model and for the learning task.\n",
        "\n",
        "\n",
        "The idea behind is that the smart application, which is able to identify if a room is occuped or not, is that it receves data from sensors through a window *W* and it predicts the occupancy state (i.e. class/label) at the last timestamp of this window.\n",
        "\n",
        "Formally, the raw data are in the following form:\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "\\mathbf{((x_1, y_1),(x_2, y_2), (x_3, y_3), ... , (x_T, y_T) )}\n",
        "\\end{align}\n",
        "\n",
        "where each $\\mathbf{x_t}$ is the value of an attribute at time $\\mathbf{t}$ , $\\mathbf{T}$ is the last timestamp of the series and $\\mathbf{y_t}$ is the label at time $\\mathbf{t}$. This class transforms the previous raw format in the following form:\n",
        "\n",
        "\\begin{align}\n",
        "\\mathbf{((x_1, x_2, x_3, ... , x_w ), y_w), ((x_2, x_3, ... , x_{w+1}), y_{w+1}), ... , ((x_{T-w}, x_{T-w+1},...,x_T), y_T)}\n",
        "\\end{align}\n",
        "\n",
        "Where $\\mathbf{w}$ represents the size of the window.\n",
        "\n",
        "\n",
        "Moreover, this transformation is able to add another feature, called **logRatio** through the method ```get_logRatio(x, index_numerator, index_denominator)``` which is the logarithmical ratio between the specified features.\n",
        "\n",
        "\n",
        "Below there is an example of how to use this class\n",
        "\n",
        "```\n",
        "S = Shrinker(window_size = 60)\n",
        "x, y = S.fit_transform(\n",
        "      df[['input_column_1','input_column_2']],\n",
        "      df['label']\n",
        "  )\n",
        "x = S.get_logRatio(x, 1, 0)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nikMtkWtRSes"
      },
      "outputs": [],
      "source": [
        "class Shrinker():\n",
        "  def __init__(self, window_size):\n",
        "\n",
        "    self.window_size = window_size\n",
        "\n",
        "\n",
        "  def fit(self):\n",
        "    return self\n",
        "\n",
        "\n",
        "  def transform(self, X, Y):\n",
        "\n",
        "    X_transformed = []\n",
        "    Y_transformed = []\n",
        "\n",
        "    # lenght of the time series\n",
        "    n_samples = len(X.axes[0])\n",
        "\n",
        "    # creation of the sequences\n",
        "    for start_idx in range(n_samples - self.window_size + 1):\n",
        "      end_idx = start_idx + self.window_size\n",
        "      sequence = X.iloc[start_idx:end_idx].to_numpy()  # extract the window\n",
        "      label = Y.iloc[end_idx - 1]       # the corresponding label\n",
        "\n",
        "\n",
        "      X_transformed.append(sequence)\n",
        "      Y_transformed.append(label)\n",
        "\n",
        "\n",
        "    X = np.asarray(X_transformed)\n",
        "    Y = np.asarray(Y_transformed)\n",
        "\n",
        "\n",
        "    return X, Y.reshape(-1, 1)  # in this way it is reshaped from (x, ) to (x, 1)\n",
        "\n",
        "\n",
        "  def fit_transform(self, X, Y):\n",
        "    return self.fit().transform(X, Y)\n",
        "\n",
        "\n",
        "\n",
        "  def get_logRatio(self, x, idx_num, idx_denom):\n",
        "    logRatio = np.log( np.divide(x[:,:,idx_num],\n",
        "                            x[:,:,idx_denom],\n",
        "                            out=np.full(x[:,:,idx_num].shape, 1e-8),\n",
        "                            where = x[:,:,idx_denom] != 0  ))   # fill with 0 where division is not valid (i.e denominator is equal to 0)\n",
        "\n",
        "    logRatio = np.expand_dims(logRatio, axis=-1)\n",
        "    return np.concatenate((x, logRatio), axis = 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA7u14V5YXSW"
      },
      "source": [
        "\n",
        "\n",
        "```OutlierEliminator()``` identifies possible outliers through the interquantile range, based on the first and last quantile from training data (i.e. this is done in the fit method). Once all possible outliers are detected, the outlier values are replaced through interpolation. It is possible to avoid this transformation on specific feature, to do so, there is ```ignored_indices``` parameter, which allows to take off them temporarlly and add them again at the end of the trasfromation. Example below:\n",
        "\n",
        "```\n",
        "O = OutlierEliminator(ignored_indices = [0, 1]) # 0-th and 1-st columns are unchanged\n",
        "x, _ = O.fit_trasform(x)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SYPFctyiRI0I"
      },
      "outputs": [],
      "source": [
        "# outlier elimination:\n",
        "# nel builder specifico l'indice della colonna delle ore e la threshold (1.5 di default)\n",
        "# nel fit ottengo i delta poi calcolo i quantili (0.25 e 0.75) e l'IRQ dei delta per ciascuna feature\n",
        "# nel transform rilevo per ciascuna serie e feature, l'indice dove ce un possibile outlier e sostituisco con l'interpolazione\n",
        "# (metodo fit_transform per completezza)\n",
        "\n",
        "class OutlierEliminator():\n",
        "  def __init__(self, ignored_indices = None, thr = 1.5):\n",
        "    self.ignored_indices = ignored_indices\n",
        "    self.thr = thr\n",
        "\n",
        "\n",
        "\n",
        "  def remove_hour_col(self, x):\n",
        "\n",
        "    self.ignored_features = list()\n",
        "\n",
        "    for i, idx in enumerate(self.ignored_indices):\n",
        "\n",
        "      self.ignored_features.append( x[:,:, idx] )\n",
        "      self.ignored_features[i] = np.expand_dims(self.ignored_features[i], axis=-1)  # reshaped from (n_series, window_size) to (n_series, window_size, 1)\n",
        "\n",
        "    x = np.delete(x, self.ignored_indices, axis=2)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "  def add_hour_col(self, x):\n",
        "\n",
        "    for feature in self.ignored_features:\n",
        "      x = np.concatenate((x, feature), axis=2)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "  def get_deltas(self, x_train):\n",
        "\n",
        "    numerator = x_train[:, 1:, :] - x_train[:, :-1, :]\n",
        "    denominator = x_train[:, :-1, :]\n",
        "\n",
        "    # here deltas will have shape (x, y-1, z)\n",
        "    deltas =  np.divide(\n",
        "                numerator,\n",
        "                denominator,\n",
        "                out=np.zeros_like(numerator),  where = denominator != 0 # fill with 0 where division is not valid\n",
        "                              )\n",
        "\n",
        "    zero_row = np.zeros((x_train.shape[0], 1, x_train.shape[2]))    # create an array of zeros with shape (x, 1, z)\n",
        "    deltas =  np.concatenate((zero_row, deltas), axis=1)   # now deltas has shape (x,y,z)\n",
        "\n",
        "\n",
        "    return deltas\n",
        "\n",
        "\n",
        "\n",
        "  def fit(self, x_train, y_train = None):\n",
        "\n",
        "    def unfold_ts(x):\n",
        "      ts = x[0, :, :]       # ts stands for time series. It starts taking the first window\n",
        "\n",
        "      for i in range(1, x.shape[0]):\n",
        "\n",
        "        # appending last value of every series to ts variable\n",
        "        conc_value = x[i, -1, :].reshape(1, -1)   # reshaped because in this way it takes shape (1, n_features) instead of (n_features, )\n",
        "        ts = np.concatenate((ts, conc_value), axis = 0)\n",
        "\n",
        "      return ts\n",
        "\n",
        "    if self.ignored_indices is not None:\n",
        "      x_train = self.remove_hour_col(x_train)\n",
        "\n",
        "    deltas = self.get_deltas(x_train)\n",
        "    deltas = unfold_ts(deltas)\n",
        "\n",
        "    self.distrib = dict()\n",
        "\n",
        "    self.distrib['Q1'] = np.quantile(deltas, 0.25, axis = 0)\n",
        "    self.distrib['Q3'] = np.quantile(deltas, 0.75, axis = 0)\n",
        "    self.distrib['IQR'] = self.distrib['Q3'] - self.distrib['Q1']\n",
        "\n",
        "    return self\n",
        "\n",
        "\n",
        "\n",
        "  def transform(self, x, y= None):\n",
        "\n",
        "    if self.ignored_indices is not None:\n",
        "      x = self.remove_hour_col(x)\n",
        "\n",
        "\n",
        "    deltas = self.get_deltas(x)\n",
        "    high_thr =  self.distrib['Q3'] + self.thr * self.distrib['IQR']\n",
        "    low_thr =   self.distrib['Q1'] - self.thr * self.distrib['IQR']\n",
        "\n",
        "\n",
        "    for series in range(0, x.shape[0]):\n",
        "      for feature in range(0, x.shape[2]):\n",
        "\n",
        "\n",
        "        # put NaN values where the deltas are above (or below) the interquantile range\n",
        "        idx_high_outliers = np.where( deltas[series, :, feature] > high_thr[feature] )[0]\n",
        "        idx_low_outliers = np.where( (deltas[series, :, feature] < low_thr[feature] ) & (deltas[series, :, feature] != 0) )[0]\n",
        "\n",
        "        if idx_high_outliers.size != 0:\n",
        "          x[series, idx_high_outliers, feature] = np.nan\n",
        "\n",
        "        if idx_low_outliers.size != 0:\n",
        "          x[series, idx_low_outliers, feature] = np.nan\n",
        "\n",
        "\n",
        "        # get values and indices of not NaN data, these are usefull for the interpolation function\n",
        "        X_not_nan = x[series, :, feature][~np.isnan( x[series, :, feature] )]\n",
        "        indices = np.where(~np.isnan( x[series, :, feature] ))[0]\n",
        "\n",
        "        # replacing NaN value through interpolation\n",
        "        x[series,:, feature] = np.interp( np.arange( 0, x.shape[1] ), indices, X_not_nan  )\n",
        "\n",
        "\n",
        "    if self.ignored_indices is not None:\n",
        "      x = self.add_hour_col(x)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "\n",
        "  def fit_transform(self, x, y = None):\n",
        "    return self.fit(x).transform(x, y)\n",
        "    #T = self.fit(x)\n",
        "\n",
        "    #return T.transform(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxZ6Krb0Yee2"
      },
      "source": [
        "```SAX_Transformer()``` enables the SAX transformation and it also do a one hot encoding on the trasformed features. The parameters for the SAX transformer are the same of the SAX transformer from pyts, for more details: https://pyts.readthedocs.io/en/latest/generated/pyts.approximation.SymbolicAggregateApproximation.html\n",
        "\n",
        "Likewise ```OutlierEliminator()```, ```SAX_Transformer()``` allows to ignore user-specified features through selecting indicies of those features.\n",
        "\n",
        "Example below:\n",
        "\n",
        "```\n",
        "T = SAX_Transformer(n_bins = 10, strategy = )\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rmXWCxb0RcPC"
      },
      "outputs": [],
      "source": [
        "# SAX transformation with OH-Encoding\n",
        "class SAX_Transformer():\n",
        "  def __init__(self, n_bins, ignored_indices = None, strategy = 'normal', ohe = True):\n",
        "    self.n_bins = n_bins\n",
        "    self.ignored_indices = ignored_indices\n",
        "    self.strategy = strategy\n",
        "    self.ohe = ohe\n",
        "\n",
        "\n",
        "  def remove_hour_col(self, x):\n",
        "\n",
        "    self.ignored_features = list()\n",
        "\n",
        "    for i, idx in enumerate(self.ignored_indices):\n",
        "      self.ignored_features.append( x[:,:, idx] )\n",
        "      self.ignored_features[i] = np.expand_dims(self.ignored_features[i], axis=-1)  # reshaped from (n_series, window_size) to (n_series, window_size, 1)\n",
        "\n",
        "    x = np.delete(x, self.ignored_indices, axis=2)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "  def add_hour_col(self, x):\n",
        "\n",
        "    for feature in self.ignored_features:\n",
        "      x = np.concatenate((x, feature), axis=2)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "  def fit(self, x, y=None):\n",
        "\n",
        "    if self.ignored_indices:\n",
        "      x = self.remove_hour_col(x)\n",
        "\n",
        "    self.sax_transformers = list()\n",
        "    n_features = x.shape[2]\n",
        "\n",
        "    # SAX transfromer initialization for every feature in x\n",
        "    self.sax_transformers = [\n",
        "          SymbolicAggregateApproximation(n_bins=self.n_bins, strategy=self.strategy).fit(x[:,:,idx_feature])\n",
        "            for idx_feature in range(n_features) ]\n",
        "    return self\n",
        "\n",
        "\n",
        "  def oh_encoding(self, data):\n",
        "\n",
        "    n_series, window_size, n_features = data.shape\n",
        "    one_hot_encoded_all_features = []\n",
        "\n",
        "    for i in range(n_features):\n",
        "      # applying one-hot encoding separatly on each feature\n",
        "      label_encoder = LabelEncoder()\n",
        "      flattened_data = data[:, :, i].ravel()\n",
        "      encoded_data = label_encoder.fit_transform(flattened_data)\n",
        "\n",
        "      # number of different letters (n_bins)\n",
        "      one_hot_encoded = np.eye(self.n_bins)[encoded_data]\n",
        "      one_hot_encoded = one_hot_encoded.reshape(n_series, window_size, self.n_bins)\n",
        "\n",
        "      one_hot_encoded_all_features.append(one_hot_encoded)\n",
        "\n",
        "    # concatenate over the feature dimension (so it will get a shape (n_series, window_size, n_bins * n_features))\n",
        "    one_hot_encoded_all_features = np.concatenate(one_hot_encoded_all_features, axis=-1)\n",
        "\n",
        "    return one_hot_encoded_all_features\n",
        "\n",
        "\n",
        "\n",
        "  def transform(self, x, y= None):\n",
        "\n",
        "    if self.ignored_indices is not None:\n",
        "      x = self.remove_hour_col(x)\n",
        "\n",
        "    n_features = x.shape[2]\n",
        "    sax_transformed = []\n",
        "    # Applying SAX to every feature\n",
        "    for i in range(n_features):\n",
        "        sax_feature = self.sax_transformers[i].transform(x[:, :, i])\n",
        "        sax_transformed.append(sax_feature)\n",
        "\n",
        "    # Stack per ottenere una nuova shape (n_timeseries, n_timestamp, n_features)\n",
        "    sax_transformed = np.stack(sax_transformed, axis=-1)\n",
        "\n",
        "    if self.ohe:\n",
        "      sax_transformed = self.oh_encoding(sax_transformed)\n",
        "\n",
        "    if self.ignored_indices is not None:\n",
        "      sax_transformed = self.add_hour_col(sax_transformed)\n",
        "\n",
        "    return sax_transformed, y\n",
        "\n",
        "\n",
        "  def fit_transform(self, x, y = None):\n",
        "    return self.fit(x, y).transform(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js7Zz9w1YmUz"
      },
      "source": [
        "The class Report simply gives a report containing the information about the predictive performance of the model through some metrics like:\n",
        "\n",
        "\n",
        "*   Accuracy\n",
        "*   Precision\n",
        "*   Recall\n",
        "*   F1-Score\n",
        "\n",
        "and a confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "umjnO8T7YZeT"
      },
      "outputs": [],
      "source": [
        "class Report():\n",
        "  def __init__(self, y_true, y_pred):\n",
        "    self.y_true = y_true\n",
        "    self.y_pred = y_pred\n",
        "    #compute metrics\n",
        "    self.accuracy = accuracy_score(self.y_true, self.y_pred)\n",
        "    self.f1_class_0 = f1_score(self.y_true, self.y_pred, pos_label=0)\n",
        "    self.f1_class_1 = f1_score(self.y_true, self.y_pred, pos_label=1)\n",
        "    self.precision_0 = precision_score(self.y_true, self.y_pred, pos_label=0)\n",
        "    self.precision_1 = precision_score(self.y_true, self.y_pred, pos_label=1)\n",
        "    self.recall_0 = recall_score(self.y_true, self.y_pred, pos_label=0)\n",
        "    self.recall_1 = recall_score(self.y_true, self.y_pred, pos_label=1)\n",
        "\n",
        "\n",
        "  def get_accuracy(self):\n",
        "    return self.accuracy\n",
        "\n",
        "  def get_f1_class_0(self):\n",
        "    return self.f1_class_0\n",
        "\n",
        "  def get_f1_class_1(self):\n",
        "    return self.f1_class_1\n",
        "\n",
        "  def get_precision_0(self):\n",
        "    return self.precision_0\n",
        "\n",
        "  def get_precision_1(self):\n",
        "    return self.precision_1\n",
        "\n",
        "  def get_recall_0(self):\n",
        "    return self.recall_0\n",
        "\n",
        "  def get_recall_1(self):\n",
        "    return self.recall_1\n",
        "\n",
        "  def show_report(self):\n",
        "    # print metrics\n",
        "    print(f\"Accuracy: {self.accuracy}\")\n",
        "    print(f\"F1-score for class 0: {self.f1_class_0}\")\n",
        "    print(f\"F1-score for class 1: {self.f1_class_1}\")\n",
        "    print(f\"Precision for class 0: {self.precision_0}\")\n",
        "    print(f\"Precision for class 1: {self.precision_1}\")\n",
        "    print(f\"Recall for class 0: {self.recall_0}\")\n",
        "    print(f\"Recall for class 1: {self.recall_1}\")\n",
        "    print(confusion_matrix(self.y_true, self.y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty6xH3BsAoMS"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wr-1HTCxloxe"
      },
      "outputs": [],
      "source": [
        "PATH= '/content/drive/MyDrive/data_mining/DM/dm2_project/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-bYiDO3A2ew",
        "outputId": "70d030e1-4e47-4708-9e3a-b100296fb26a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "P = Preprocessing(PATH, 'training_ts.csv', 'test_ts.csv')\n",
        "train = P.get_train()\n",
        "test = P.get_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqXMXrxtA1PP"
      },
      "source": [
        "# Shrinking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_9ZG0AHiA0yW"
      },
      "outputs": [],
      "source": [
        "S = Shrinker(window_size = 60)\n",
        "\n",
        "x_train_shrinked, y_train_shrinked = S.fit_transform(train[['Light', 'CO2', 'hour']], train['Occupancy'])\n",
        "x_test_shrinked, y_test_shrinked = S.transform(test[['Light', 'CO2', 'hour']], test['Occupancy'])\n",
        "\n",
        "x_train_shrinked = S.get_logRatio(x_train_shrinked, 1, 0)\n",
        "x_test_shrinked = S.get_logRatio(x_test_shrinked, 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_cbct8rApkZ"
      },
      "source": [
        "# Outlier elimination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "13pG8qz6dwTK"
      },
      "outputs": [],
      "source": [
        "O = OutlierEliminator(ignored_indices = [2,3])\n",
        "\n",
        "x_train_shrinked, _ = O.fit_transform(x_train_shrinked)\n",
        "x_test_shrinked, _ = O.transform(x_test_shrinked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxcPOFwYet4Y"
      },
      "source": [
        "# SAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VlkfkmP5QTAb"
      },
      "outputs": [],
      "source": [
        "SAX = SAX_Transformer(n_bins = 8, ignored_indices = [2,3])\n",
        "\n",
        "x_train_sax, _ = SAX.fit_transform(x_train_shrinked)\n",
        "x_test_sax, _ = SAX.transform(x_test_shrinked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SAdFEN3hTdP"
      },
      "source": [
        "# Model selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF0V2_ZkGIea"
      },
      "source": [
        "The fitting process for all the models described below follows the same approach, utilizing the classes ```Shrinker()```, ```OutlierEliminator()```, and ```SAX_Transformer()```. These classes have their parameters fine-tuned by the tuner to determine the optimal input shape that maximizes the model's performance. Initially, the dataset is divided using a standard hold-out method, allocating 15% of the training data for validation. After identifying the best configuration, the model undergoes a thorough evaluation using k-fold cross-validation (as detailed in the Cross-Validation section) to ensure robustness, and its final performance is assessed on the designated test set (refer to the Model Evaluation section)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1fZWFT-uRGa"
      },
      "source": [
        "## Best model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MzSGULa8Djg"
      },
      "source": [
        "This model uses 4 features, namely Light, CO2, hour and logRatio. Then, it combines each feature with the hour feature, in this way it is possible for the model to learn the relationship between these features (i.e. light, CO2 and this log ratio of light and CO2) and the time component (i.e. the hour in that day). This is done by just applying a concatenation.\n",
        "\n",
        "This process involves passing each feature through its own LSTM layers that are specifically designed to model the interaction between that feature and the hour feature. There are four distinct sets of LSTM layers: one for Light combined with Hour, one for CO2 combined with Hour, one dedicated solely to the log ratio, and one for the interaction between the log ratio and Hour. Each LSTM set focuses on learning the temporal patterns and dependencies unique to the combination of the respective feature and the hour of the day.\n",
        "\n",
        "After this sets of LSTMs, the model concatenates the results of the different LSTMs and condensate them with a Deep Farward Neural Network. The last layer of this DFNN it does a sigmoid, so it can do binary classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "R3TDhKlouWd1"
      },
      "outputs": [],
      "source": [
        "class Model_wHours_ratio(kt.HyperModel):\n",
        "\n",
        "  def build(self, hp):\n",
        "\n",
        "      # it defines the widows size and the number of bin for the SAX\n",
        "      window = hp.Int('window', 30, 120, step=10)\n",
        "      n_bins = hp.Int('n_bins', 5, 10, step=1)\n",
        "\n",
        "\n",
        "      input_shape = (window, n_bins)\n",
        "\n",
        "      # inputs layer\n",
        "      feature1 = Input(shape=input_shape, name=\"feature_1\")\n",
        "      feature2 = Input(shape=input_shape, name=\"feature_2\")\n",
        "      hours = Input(shape=(window, 1), name=\"hours\")\n",
        "      ratio = Input(shape=(window, 1), name=\"feature3\")\n",
        "\n",
        "      ratio = LayerNormalization()(ratio)\n",
        "\n",
        "      # concatenate each feature with hours\n",
        "      feature1_with_hours = Concatenate()([feature1, hours])\n",
        "      feature2_with_hours = Concatenate()([feature2, hours])\n",
        "      ratio_with_hours = Concatenate()([ratio, hours])\n",
        "\n",
        "\n",
        "\n",
        "      # LSTM layers\n",
        "      lstm_first = True\n",
        "      n_lstm_layers = hp.Int('num_lstm_layers', 1, 10)\n",
        "      for lstm_layer in range(n_lstm_layers):\n",
        "\n",
        "        # it checks if it is on the last layer of LSTM\n",
        "        if lstm_layer + 1 == n_lstm_layers:\n",
        "          flag_sequence = False\n",
        "        else:\n",
        "          flag_sequence = True\n",
        "\n",
        "\n",
        "        if lstm_first:\n",
        "          lstmFeature1 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 1 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 1 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(feature1_with_hours)\n",
        "\n",
        "          lstmFeature2 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 2 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 2 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(feature2_with_hours)\n",
        "\n",
        "          lstmFeature3 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 3 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 3 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(ratio)\n",
        "\n",
        "          lstmFeature3_hours = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 3(hours) units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 3(hours) l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(ratio_with_hours)\n",
        "\n",
        "        else:\n",
        "          lstmFeature1 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 1 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 1 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(lstmFeature1)\n",
        "\n",
        "          lstmFeature2 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 2 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 2 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(lstmFeature2)\n",
        "\n",
        "          lstmFeature3 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 3 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 3 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(lstmFeature3)\n",
        "\n",
        "          lstmFeature3_hours = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 3(hours) units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 3(hours) l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(lstmFeature3_hours)\n",
        "\n",
        "\n",
        "        # Dropout for each LSTM layer\n",
        "        if hp.Boolean(f'{lstm_layer + 1} layer lstm dropout'):\n",
        "          lstmFeature1 = Dropout(hp.Float(f'{lstm_layer + 1} lstm layer feature 1 dropout_rate', 0.1, 0.5, step=0.1))(lstmFeature1)\n",
        "          lstmFeature2 = Dropout(hp.Float(f'{lstm_layer + 1} lstm layer feature 2 dropout_rate', 0.1, 0.5, step=0.1))(lstmFeature2)\n",
        "          lstmFeature3 = Dropout(hp.Float(f'{lstm_layer + 1} lstm layer feature 3 dropout_rate', 0.1, 0.5, step=0.1))(lstmFeature3)\n",
        "          lstmFeature3_hours = Dropout(hp.Float(f'{lstm_layer + 1} lstm layer feature 3(hours) dropout_rate', 0.1, 0.5, step=0.1))(lstmFeature3_hours)\n",
        "\n",
        "      # merging the two LSTM layers\n",
        "      x = Concatenate()([lstmFeature1, lstmFeature2, lstmFeature3,  lstmFeature3_hours])\n",
        "      x = Dense(hp.Int('dim_reduction_layer__units', 1, x.shape[1]//2, step=1), activation='relu',\n",
        "                kernel_regularizer = l2(hp.Float('dense dim reduction l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(x)  # it helps to reduce the dimensionality\n",
        "\n",
        "\n",
        "      # perceptron layers\n",
        "      num_hidden_layers = hp.Int('num_hidden_layers', 1, 5)\n",
        "      for layer in range(num_hidden_layers):\n",
        "\n",
        "          x = Dense(hp.Int(f'{layer + 1} dense layer units', 4, 64, step=4), activation='relu',\n",
        "                     kernel_regularizer = l2(hp.Float(f'{lstm_layer + 1} dense layer l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(x)\n",
        "          x = Dropout(hp.Float(f'{layer + 1} dropout_rate', 0, 0.5, step=0.1))(x)\n",
        "\n",
        "      # output layer\n",
        "      output = Dense(1, activation='sigmoid', kernel_regularizer= l2(hp.Float('output layer l2_reg', min_value=1e-5, max_value=1e-2, sampling='log')))(x)\n",
        "\n",
        "\n",
        "      # compiling\n",
        "      model = Model(inputs=[feature1, feature2, hours, ratio], outputs=output)\n",
        "      model.compile(optimizer=keras.optimizers.Adam(\n",
        "          learning_rate=hp.Float('lr', 1e-4, 1e-2, sampling='LOG'), ema_momentum=hp.Float('momentum', 1e-4, 1e-2, sampling='LOG')),\n",
        "          loss=BinaryCrossentropy(),\n",
        "          metrics=[AUC()])\n",
        "      return model\n",
        "\n",
        "\n",
        "                                  # as perc float    # as tuple\n",
        "  def fit(self, hp, model, x, y, val_split = None, n_bins = None, window_size = None, **kwargs):\n",
        "\n",
        "    if window_size is None:\n",
        "      window_size = hp.get('window')\n",
        "    if n_bins is None:\n",
        "      n_bins= hp.get('n_bins')\n",
        "\n",
        "    S = Shrinker(window_size)\n",
        "    O = OutlierEliminator(ignored_indices = [2,3])\n",
        "    SAX_trans = SAX_Transformer(n_bins, ignored_indices = [2,3])\n",
        "\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size= val_split, shuffle= False)\n",
        "\n",
        "\n",
        "    x_train, y_train = S.fit_transform(x_train, y_train)\n",
        "    x_train = S.get_logRatio(x_train, 1,0)\n",
        "\n",
        "    O.fit(x_train)\n",
        "    x_train, _ = O.transform(x_train, y_train)\n",
        "\n",
        "    SAX_trans.fit(x_train)\n",
        "    x_train, _ = SAX_trans.transform(x_train, y_train)\n",
        "\n",
        "\n",
        "    x_val, y_val = S.transform(x_val, y_val)\n",
        "    x_val = S.get_logRatio(x_val, 1,0)\n",
        "    x_val, _ = O.transform(x_val, y_val)\n",
        "    x_val, _ = SAX_trans.transform(x_val, y_val)\n",
        "\n",
        "\n",
        "    input_vars_train = [x_train[:, :, 0: n_bins], x_train[:, :, n_bins:n_bins*2], x_train[:, :, n_bins*2], x_train[:, :, n_bins*2 +1]]\n",
        "    input_vars_val = [x_val[:, :, 0: n_bins], x_val[:, :, n_bins:n_bins*2], x_val[:, :, n_bins*2], x_val[:, :, n_bins*2 +1]]\n",
        "\n",
        "\n",
        "    return model.fit(x = input_vars_train, y = y_train, validation_data=(input_vars_val, y_val), **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr_jq5R9HANP"
      },
      "source": [
        "In this trial the input feature are ```Light```, ```CO2```, the ```hour``` and their logarithmic ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12UsJ4ZsQoES",
        "outputId": "70b16cbc-305f-423c-9ea3-267b5ebe17f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from model selction/light-co2-hours_ratio_hb_new/tuner0.json\n"
          ]
        }
      ],
      "source": [
        "tuner_best_model = kt.Hyperband(\n",
        "    Model_wHours_ratio(),\n",
        "    objective=kt.Objective('val_loss', direction=\"min\"),\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    seed= 42,\n",
        "    directory='model selction',\n",
        "    project_name='light-co2-hours_ratio_hb_new'\n",
        ")\n",
        "\n",
        "\n",
        "tuner_best_model.search(x =train[['Light', 'CO2', 'hour']], y = train['Occupancy'], epochs=5, val_split=0.15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzuG41gWGhzP"
      },
      "source": [
        "In this trial the input feature are ```Light```, ```Humidity```, the ```hour``` and their logarithmic ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz5wV7EtGgXY",
        "outputId": "53139a91-93d9-4f01-e0d4-d6b62a55b1ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 26 Complete [00h 07m 19s]\n",
            "val_loss: 0.07181131839752197\n",
            "\n",
            "Best val_loss So Far: 0.04450763016939163\n",
            "Total elapsed time: 01h 07m 28s\n",
            "\n",
            "Search: Running Trial #27\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "110               |40                |window\n",
            "7                 |6                 |n_bins\n",
            "2                 |3                 |num_lstm_layers\n",
            "10                |55                |1 lstm layer feature 1 units\n",
            "0.00028213        |0.0001294         |1 lstm layer feature 1 l2_reg\n",
            "25                |55                |1 lstm layer feature 2 units\n",
            "0.0025305         |1.8533e-05        |1 lstm layer feature 2 l2_reg\n",
            "45                |65                |1 lstm layer feature 3 units\n",
            "0.058597          |4.1017e-05        |1 lstm layer feature 3 l2_reg\n",
            "35                |45                |1 lstm layer feature 3(hours) units\n",
            "0.0001191         |1.3543e-06        |1 lstm layer feature 3(hours) l2_reg\n",
            "False             |True              |1 layer lstm dropout\n",
            "3                 |4                 |dim_reduction_layer__units\n",
            "0.00076848        |4.1218e-05        |dense dim reduction l2_reg\n",
            "2                 |3                 |num_hidden_layers\n",
            "20                |28                |1 dense layer units\n",
            "6.9035e-06        |6.5571e-06        |1 dense layer l2_reg\n",
            "0                 |0                 |1 dropout_rate\n",
            "0.0006305         |5.8173e-05        |output layer l2_reg\n",
            "0.0015463         |0.0015453         |lr\n",
            "0.0008156         |0.00034986        |momentum\n",
            "0.4               |0.5               |1 lstm layer feature 1 dropout_rate\n",
            "0.3               |0.3               |1 lstm layer feature 2 dropout_rate\n",
            "0.4               |0.1               |1 lstm layer feature 3 dropout_rate\n",
            "0.1               |0.2               |1 lstm layer feature 3(hours) dropout_rate\n",
            "55                |65                |2 lstm layer feature 1 units\n",
            "0.00061537        |8.1493e-05        |2 lstm layer feature 1 l2_reg\n",
            "35                |35                |2 lstm layer feature 2 units\n",
            "7.6501e-05        |1.0972e-05        |2 lstm layer feature 2 l2_reg\n",
            "45                |30                |2 lstm layer feature 3 units\n",
            "0.084289          |4.1811e-06        |2 lstm layer feature 3 l2_reg\n",
            "15                |15                |2 lstm layer feature 3(hours) units\n",
            "0.070104          |6.7926e-05        |2 lstm layer feature 3(hours) l2_reg\n",
            "True              |True              |2 layer lstm dropout\n",
            "40                |25                |3 lstm layer feature 1 units\n",
            "0.00023386        |0.00056769        |3 lstm layer feature 1 l2_reg\n",
            "60                |55                |3 lstm layer feature 2 units\n",
            "0.050372          |0.00011353        |3 lstm layer feature 2 l2_reg\n",
            "30                |20                |3 lstm layer feature 3 units\n",
            "2.8739e-05        |8.9629e-06        |3 lstm layer feature 3 l2_reg\n",
            "60                |10                |3 lstm layer feature 3(hours) units\n",
            "0.0091555         |1.5923e-06        |3 lstm layer feature 3(hours) l2_reg\n",
            "True              |False             |3 layer lstm dropout\n",
            "40                |20                |4 lstm layer feature 1 units\n",
            "0.0002132         |3.2786e-05        |4 lstm layer feature 1 l2_reg\n",
            "50                |60                |4 lstm layer feature 2 units\n",
            "0.0019792         |0.0055082         |4 lstm layer feature 2 l2_reg\n",
            "35                |50                |4 lstm layer feature 3 units\n",
            "2.5846e-05        |2.2719e-06        |4 lstm layer feature 3 l2_reg\n",
            "40                |65                |4 lstm layer feature 3(hours) units\n",
            "0.023773          |3.0984e-05        |4 lstm layer feature 3(hours) l2_reg\n",
            "False             |True              |4 layer lstm dropout\n",
            "25                |40                |5 lstm layer feature 1 units\n",
            "8.9093e-05        |1.0456e-05        |5 lstm layer feature 1 l2_reg\n",
            "30                |20                |5 lstm layer feature 2 units\n",
            "0.087515          |9.0863e-06        |5 lstm layer feature 2 l2_reg\n",
            "35                |60                |5 lstm layer feature 3 units\n",
            "0.00010081        |1.8297e-05        |5 lstm layer feature 3 l2_reg\n",
            "25                |65                |5 lstm layer feature 3(hours) units\n",
            "2.0393e-05        |2.1265e-05        |5 lstm layer feature 3(hours) l2_reg\n",
            "True              |False             |5 layer lstm dropout\n",
            "0.00020828        |0.081351          |5 dense layer l2_reg\n",
            "56                |60                |2 dense layer units\n",
            "0                 |0.1               |2 dropout_rate\n",
            "28                |8                 |3 dense layer units\n",
            "0.1               |0.4               |3 dropout_rate\n",
            "32                |32                |4 dense layer units\n",
            "0.2               |0.3               |4 dropout_rate\n",
            "28                |64                |5 dense layer units\n",
            "0.3               |0.4               |5 dropout_rate\n",
            "0.4               |0.2               |3 lstm layer feature 1 dropout_rate\n",
            "0.5               |0.4               |3 lstm layer feature 2 dropout_rate\n",
            "0.1               |0.3               |3 lstm layer feature 3 dropout_rate\n",
            "0.4               |0.3               |3 lstm layer feature 3(hours) dropout_rate\n",
            "0.3               |0.3               |5 lstm layer feature 1 dropout_rate\n",
            "0.2               |0.1               |5 lstm layer feature 2 dropout_rate\n",
            "0.5               |0.1               |5 lstm layer feature 3 dropout_rate\n",
            "0.1               |0.5               |5 lstm layer feature 3(hours) dropout_rate\n",
            "30                |10                |6 lstm layer feature 1 units\n",
            "0.0034929         |0.049495          |6 lstm layer feature 1 l2_reg\n",
            "35                |60                |6 lstm layer feature 2 units\n",
            "2.3584e-06        |0.00030065        |6 lstm layer feature 2 l2_reg\n",
            "65                |55                |6 lstm layer feature 3 units\n",
            "0.0042336         |0.03048           |6 lstm layer feature 3 l2_reg\n",
            "5                 |45                |6 lstm layer feature 3(hours) units\n",
            "1.7855e-06        |0.0026471         |6 lstm layer feature 3(hours) l2_reg\n",
            "True              |True              |6 layer lstm dropout\n",
            "10                |20                |7 lstm layer feature 1 units\n",
            "0.00014245        |0.00025719        |7 lstm layer feature 1 l2_reg\n",
            "20                |10                |7 lstm layer feature 2 units\n",
            "0.00012642        |0.0096981         |7 lstm layer feature 2 l2_reg\n",
            "25                |45                |7 lstm layer feature 3 units\n",
            "8.8069e-05        |0.00033692        |7 lstm layer feature 3 l2_reg\n",
            "30                |15                |7 lstm layer feature 3(hours) units\n",
            "0.027619          |0.00020634        |7 lstm layer feature 3(hours) l2_reg\n",
            "False             |False             |7 layer lstm dropout\n",
            "5.0703e-05        |0.0061227         |7 dense layer l2_reg\n",
            "0.5               |0.3               |2 lstm layer feature 1 dropout_rate\n",
            "0.5               |0.3               |2 lstm layer feature 2 dropout_rate\n",
            "0.5               |0.4               |2 lstm layer feature 3 dropout_rate\n",
            "0.5               |0.4               |2 lstm layer feature 3(hours) dropout_rate\n",
            "0.3               |0.1               |4 lstm layer feature 1 dropout_rate\n",
            "0.4               |0.1               |4 lstm layer feature 2 dropout_rate\n",
            "0.5               |0.1               |4 lstm layer feature 3 dropout_rate\n",
            "0.2               |0.2               |4 lstm layer feature 3(hours) dropout_rate\n",
            "1.2994e-06        |6.6585e-06        |6 dense layer l2_reg\n",
            "0.00030117        |1e-06             |3 dense layer l2_reg\n",
            "0.4               |0.3               |7 lstm layer feature 1 dropout_rate\n",
            "0.2               |0.5               |7 lstm layer feature 2 dropout_rate\n",
            "0.5               |0.3               |7 lstm layer feature 3 dropout_rate\n",
            "0.3               |0.2               |7 lstm layer feature 3(hours) dropout_rate\n",
            "45                |35                |8 lstm layer feature 1 units\n",
            "3.7432e-05        |2.0699e-05        |8 lstm layer feature 1 l2_reg\n",
            "25                |50                |8 lstm layer feature 2 units\n",
            "3.6098e-06        |0.0065959         |8 lstm layer feature 2 l2_reg\n",
            "65                |20                |8 lstm layer feature 3 units\n",
            "0.0018055         |1.7517e-06        |8 lstm layer feature 3 l2_reg\n",
            "45                |55                |8 lstm layer feature 3(hours) units\n",
            "8.7409e-05        |0.00053921        |8 lstm layer feature 3(hours) l2_reg\n",
            "True              |False             |8 layer lstm dropout\n",
            "55                |25                |9 lstm layer feature 1 units\n",
            "0.00033085        |1.0543e-06        |9 lstm layer feature 1 l2_reg\n",
            "35                |40                |9 lstm layer feature 2 units\n",
            "1.3451e-06        |0.0064207         |9 lstm layer feature 2 l2_reg\n",
            "35                |15                |9 lstm layer feature 3 units\n",
            "7.6318e-05        |0.086654          |9 lstm layer feature 3 l2_reg\n",
            "25                |60                |9 lstm layer feature 3(hours) units\n",
            "0.00014165        |0.0011239         |9 lstm layer feature 3(hours) l2_reg\n",
            "False             |False             |9 layer lstm dropout\n",
            "30                |5                 |10 lstm layer feature 1 units\n",
            "7.0586e-05        |0.018426          |10 lstm layer feature 1 l2_reg\n",
            "65                |30                |10 lstm layer feature 2 units\n",
            "0.012119          |6.2193e-06        |10 lstm layer feature 2 l2_reg\n",
            "10                |10                |10 lstm layer feature 3 units\n",
            "0.0002664         |4.7106e-06        |10 lstm layer feature 3 l2_reg\n",
            "20                |15                |10 lstm layer feature 3(hours) units\n",
            "9.2766e-06        |0.00049688        |10 lstm layer feature 3(hours) l2_reg\n",
            "False             |False             |10 layer lstm dropout\n",
            "1.2386e-05        |0.090507          |10 dense layer l2_reg\n",
            "0.3               |0.2               |6 lstm layer feature 1 dropout_rate\n",
            "0.3               |0.2               |6 lstm layer feature 2 dropout_rate\n",
            "0.5               |0.3               |6 lstm layer feature 3 dropout_rate\n",
            "0.4               |0.2               |6 lstm layer feature 3(hours) dropout_rate\n",
            "0.2               |0.1               |9 lstm layer feature 1 dropout_rate\n",
            "0.5               |0.1               |9 lstm layer feature 2 dropout_rate\n",
            "0.5               |0.2               |9 lstm layer feature 3 dropout_rate\n",
            "0.1               |0.5               |9 lstm layer feature 3(hours) dropout_rate\n",
            "0.1               |0.1               |8 lstm layer feature 1 dropout_rate\n",
            "0.3               |0.5               |8 lstm layer feature 2 dropout_rate\n",
            "0.3               |0.4               |8 lstm layer feature 3 dropout_rate\n",
            "0.2               |0.1               |8 lstm layer feature 3(hours) dropout_rate\n",
            "0.1               |0.5               |10 lstm layer feature 1 dropout_rate\n",
            "0.2               |0.5               |10 lstm layer feature 2 dropout_rate\n",
            "0.2               |0.5               |10 lstm layer feature 3 dropout_rate\n",
            "0.2               |0.1               |10 lstm layer feature 3(hours) dropout_rate\n",
            "0.00011044        |1.07e-06          |9 dense layer l2_reg\n",
            "9.57e-05          |None              |2 dense layer l2_reg\n",
            "10                |4                 |tuner/epochs\n",
            "0                 |2                 |tuner/initial_epoch\n",
            "0                 |2                 |tuner/bracket\n",
            "0                 |1                 |tuner/round\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 155ms/step - auc: 0.8913 - loss: 0.4939 - val_auc: 0.9960 - val_loss: 0.0985\n",
            "Epoch 2/10\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 154ms/step - auc: 0.9697 - loss: 0.1733 - val_auc: 0.9972 - val_loss: 0.1012\n",
            "Epoch 3/10\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 154ms/step - auc: 0.9699 - loss: 0.1650 - val_auc: 0.9979 - val_loss: 0.0837\n",
            "Epoch 4/10\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - auc: 0.9767 - loss: 0.1465 - val_auc: 0.9981 - val_loss: 0.0875\n",
            "Epoch 5/10\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 155ms/step - auc: 0.9752 - loss: 0.1576 - val_auc: 0.9980 - val_loss: 0.0637\n",
            "Epoch 6/10\n"
          ]
        }
      ],
      "source": [
        "tuner_best_model = kt.Hyperband(\n",
        "    Model_wHours_ratio(),\n",
        "    objective=kt.Objective('val_loss', direction=\"min\"),\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    seed= 42,\n",
        "    directory='model selction',\n",
        "    project_name='light-humidity-hours_ratio_lstm'\n",
        ")\n",
        "\n",
        "\n",
        "tuner_best_model.search(x =train[['Light', 'Humidity', 'hour']], y = train['Occupancy'], epochs=5, val_split=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g1XvlsvOX_W1",
        "outputId": "200bb53f-e17b-40d3-f422-64bd7ce71be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " feature_1 (\u001b[38;5;33mInputLayer\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m6\u001b[0m)                        \u001b[38;5;34m0\u001b[0m  -                      \n",
              "\n",
              " hours (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m1\u001b[0m)                        \u001b[38;5;34m0\u001b[0m  -                      \n",
              "\n",
              " feature_2 (\u001b[38;5;33mInputLayer\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m6\u001b[0m)                        \u001b[38;5;34m0\u001b[0m  -                      \n",
              "\n",
              " keras_tensorCLONE          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m1\u001b[0m)                        \u001b[38;5;34m0\u001b[0m  -                      \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                                              \n",
              "\n",
              " concatenate (\u001b[38;5;33mConcatenate\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m7\u001b[0m)                        \u001b[38;5;34m0\u001b[0m  feature_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              "                                                                    hours[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "\n",
              " concatenate_1              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m7\u001b[0m)                        \u001b[38;5;34m0\u001b[0m  feature_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                                      hours[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "\n",
              " concatenate_2              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m2\u001b[0m)                        \u001b[38;5;34m0\u001b[0m  keras_tensorCLONE[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                                      hours[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "\n",
              " lstm_32 (\u001b[38;5;33mLSTM\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                       \u001b[38;5;34m4,560\u001b[0m  concatenate[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " lstm_33 (\u001b[38;5;33mLSTM\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                       \u001b[38;5;34m3,300\u001b[0m  concatenate_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " lstm_34 (\u001b[38;5;33mLSTM\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                          \u001b[38;5;34m140\u001b[0m  keras_tensorCLONE[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "\n",
              " lstm_35 (\u001b[38;5;33mLSTM\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)                       \u001b[38;5;34m8,640\u001b[0m  concatenate_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " dropout_20 (\u001b[38;5;33mDropout\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                           \u001b[38;5;34m0\u001b[0m  lstm_32[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
              "\n",
              " dropout_21 (\u001b[38;5;33mDropout\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                           \u001b[38;5;34m0\u001b[0m  lstm_33[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
              "\n",
              " dropout_22 (\u001b[38;5;33mDropout\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                            \u001b[38;5;34m0\u001b[0m  lstm_34[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
              "\n",
              " dropout_23 (\u001b[38;5;33mDropout\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)                           \u001b[38;5;34m0\u001b[0m  lstm_35[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
              "\n",
              " concatenate_3              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m105\u001b[0m)                          \u001b[38;5;34m0\u001b[0m  dropout_20[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                                      dropout_21[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
              "                                                                    dropout_22[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
              "                                                                    dropout_23[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                          \u001b[38;5;34m318\u001b[0m  concatenate_3[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                           \u001b[38;5;34m16\u001b[0m  dense[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "\n",
              " dropout_24 (\u001b[38;5;33mDropout\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                            \u001b[38;5;34m0\u001b[0m  dense_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
              "\n",
              " dense_2 (\u001b[38;5;33mDense\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                         \u001b[38;5;34m240\u001b[0m  dropout_24[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              "\n",
              " dropout_25 (\u001b[38;5;33mDropout\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                           \u001b[38;5;34m0\u001b[0m  dense_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
              "\n",
              " dense_3 (\u001b[38;5;33mDense\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                       \u001b[38;5;34m2,352\u001b[0m  dropout_25[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              "\n",
              " dropout_26 (\u001b[38;5;33mDropout\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                           \u001b[38;5;34m0\u001b[0m  dense_3[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
              "\n",
              " dense_4 (\u001b[38;5;33mDense\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                         \u001b[38;5;34m588\u001b[0m  dropout_26[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              "\n",
              " dropout_27 (\u001b[38;5;33mDropout\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                           \u001b[38;5;34m0\u001b[0m  dense_4[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
              "\n",
              " dense_5 (\u001b[38;5;33mDense\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                           \u001b[38;5;34m13\u001b[0m  dropout_27[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)              </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">        Param # </span><span style=\"font-weight: bold\"> Connected to           </span>\n",
              "\n",
              " feature_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                      \n",
              "\n",
              " hours (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                      \n",
              "\n",
              " feature_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                      \n",
              "\n",
              " keras_tensorCLONE          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                                              \n",
              "\n",
              " concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  feature_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              "                                                                    hours[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "\n",
              " concatenate_1              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  feature_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                                      hours[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "\n",
              " concatenate_2              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  keras_tensorCLONE[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                                      hours[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "\n",
              " lstm_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,560</span>  concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " lstm_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,300</span>  concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " lstm_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>  keras_tensorCLONE[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "\n",
              " lstm_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,640</span>  concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lstm_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
              "\n",
              " dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lstm_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
              "\n",
              " dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lstm_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
              "\n",
              " dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lstm_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
              "\n",
              " concatenate_3              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dropout_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                                      dropout_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
              "                                                                    dropout_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
              "                                                                    dropout_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">318</span>  concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>  dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "\n",
              " dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
              "\n",
              " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>  dropout_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              "\n",
              " dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
              "\n",
              " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,352</span>  dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              "\n",
              " dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
              "\n",
              " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">588</span>  dropout_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              "\n",
              " dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
              "\n",
              " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>  dropout_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,167\u001b[0m (78.78 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,167</span> (78.78 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,167\u001b[0m (78.78 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,167</span> (78.78 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "best_hp = tuner_best_model.get_best_hyperparameters()[0].values\n",
        "window_size = best_hp['window']\n",
        "n_bins = best_hp['n_bins']    # these will be usefull next\n",
        "\n",
        "\n",
        "best_model = tuner_best_model.get_best_models(num_models=1)[0]\n",
        "best_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCVg_Z-KuSsd"
      },
      "source": [
        "## Other models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWG0inVBJwho"
      },
      "source": [
        "In this section, we explore two other different models to predict room occupancy, each designed with varying architectures and features. The goal is to evaluate the impact of specific features and network layers on the overall model performance.\n",
        "\n",
        "**Models Explored:**\n",
        "\n",
        "**Model with CNN Layers:** Incorporates Convolutional Neural Network (CNN) layers.\n",
        "\n",
        "**Model with Hour Feature Only:** Focuses on leveraging the hour feature without additional feature transformations.\n",
        "\n",
        "**Best Model (LSTM with Logarithmic Ratio):** Combines Long Short-Term Memory (LSTM) layers with the logarithmic ratio of features (Light and CO2) and the hour feature, achieving the highest performance.\n",
        "\n",
        "**Key Findings:**\n",
        "\n",
        "The first two models demonstrated lower performance compared to the best model.\n",
        "\n",
        "Incorporating the logarithmic ratio of features alongside the hour feature in the best model significantly enhanced accuracy and F1 scores.\n",
        "\n",
        "Through this comparison, we demonstrate how thoughtful feature engineering and the appropriate choice of model architecture can improve predictive performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEp3J25vL3C_"
      },
      "source": [
        "### CNN-LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIhl723-uW2H"
      },
      "outputs": [],
      "source": [
        "class CNN_LSTM_Model(kt.HyperModel):\n",
        "  def build(self, hp):\n",
        "      # it defines the widows size and the number of bin for the SAX\n",
        "      window_size = hp.Int('window', 30, 120, step=10)\n",
        "      n_bins = hp.Int('n_bins', 5, 10, step=1)\n",
        "\n",
        "      # defining cnn paramters here because otherwise they won't be tweaked idk why\n",
        "      cnn_filters_feature_1 = hp.Int('cnn filters feature 1', 1, 5, step=1)\n",
        "      cnn_filters_feature_2 = hp.Int('cnn filters feature 2', 1, 5, step=1)\n",
        "      kernel_size_feature_1 = hp.Int('kernel_size feature 1', 2, 5, step=1)\n",
        "      kernel_size_feature_2 = hp.Int('kernel_size feature 2', 2, 5, step=1)\n",
        "      pool_size_feature_1 = hp.Int('pool_size feature 1', 2, 5, step=1)\n",
        "      pool_size_feature_2 = hp.Int('pool_size feature 2', 2, 5, step=1)\n",
        "\n",
        "\n",
        "      input_shape = (window_size, n_bins)\n",
        "\n",
        "      # inputs layer\n",
        "      feature1 = Input(shape=input_shape, name=\"feature_1\")\n",
        "      feature2 = Input(shape=input_shape, name=\"feature_2\")\n",
        "\n",
        "\n",
        "      # CNN as an embedding layer\n",
        "      if hp.Boolean('cnn'):\n",
        "\n",
        "        cnn1 = Conv1D(filters = cnn_filters_feature_1, kernel_size = kernel_size_feature_1, activation='relu',\n",
        "                      kernel_regularizer= l2(hp.Float('cnn feature 1 l2_reg', min_value=1e-5, max_value=1e-2, sampling='log')))(feature1)\n",
        "\n",
        "        cnn2 = Conv1D(filters = cnn_filters_feature_2, kernel_size = kernel_size_feature_2, activation='relu',\n",
        "                      kernel_regularizer= l2(hp.Float('cnn feature 1 l2_reg', min_value=1e-5, max_value=1e-2, sampling='log')))(feature2)\n",
        "\n",
        "        # pooling layers\n",
        "        if hp.Boolean('avg_pool'):\n",
        "          cnn1 = AveragePooling1D(pool_size_feature_1)(cnn1)\n",
        "          cnn2 = AveragePooling1D(pool_size_feature_2)(cnn2)\n",
        "        else:\n",
        "          cnn1 = MaxPooling1D(pool_size_feature_1)(cnn1)\n",
        "          cnn2 = MaxPooling1D(pool_size_feature_2)(cnn2)\n",
        "\n",
        "\n",
        "      # LSTM layers\n",
        "      lstm_first = True\n",
        "      n_lstm_layers = hp.Int('num_lstm_layers', 1, 10)\n",
        "      for lstm_layer in range(n_lstm_layers):\n",
        "\n",
        "        # it checks if it is on the last layer of LSTM\n",
        "        if lstm_layer + 1 == n_lstm_layers:\n",
        "          flag_sequence = False\n",
        "        else:\n",
        "          flag_sequence = True\n",
        "\n",
        "\n",
        "        if lstm_first:\n",
        "          lstmFeature1 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 1 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 1 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(cnn1 if hp.Boolean('cnn') else feature1)\n",
        "\n",
        "          lstmFeature2 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 2 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 2 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(cnn2 if hp.Boolean('cnn') else feature2)\n",
        "\n",
        "\n",
        "        else:\n",
        "          lstmFeature1 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 1 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 1 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(lstmFeature1)\n",
        "\n",
        "          lstmFeature2 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 2 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 2 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(lstmFeature2)\n",
        "\n",
        "\n",
        "\n",
        "        # Dropout for each LSTM layer\n",
        "        if hp.Boolean(f'{lstm_layer + 1} layer lstm dropout'):\n",
        "          lstmFeature1 = Dropout(hp.Float(f'{lstm_layer + 1} lstm layer feature 1 dropout_rate', 0.1, 0.5, step=0.1))(lstmFeature1)\n",
        "          lstmFeature2 = Dropout(hp.Float(f'{lstm_layer + 1} lstm layer feature 2 dropout_rate', 0.1, 0.5, step=0.1))(lstmFeature2)\n",
        "\n",
        "      # merging the two LSTM layers\n",
        "      x = Concatenate()([lstmFeature1, lstmFeature2])\n",
        "      x = Dense(hp.Int('dim_reduction_layer__units', 1, x.shape[1]//2, step=1), activation='relu',\n",
        "                kernel_regularizer = l2(hp.Float('dense dim reduction l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(x)  # it helps to reduce the dimensionality\n",
        "\n",
        "\n",
        "      # perceptron layers\n",
        "      num_hidden_layers = hp.Int('num_hidden_layers', 1, 5)\n",
        "      for layer in range(num_hidden_layers):\n",
        "\n",
        "          x = Dense(hp.Int(f'{layer + 1} dense layer units', 4, 64, step=4), activation='relu',\n",
        "                     kernel_regularizer = l2(hp.Float(f'{lstm_layer + 1} dense layer l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(x)\n",
        "          x = Dropout(hp.Float(f'{layer + 1} dropout_rate', 0, 0.5, step=0.1))(x)\n",
        "\n",
        "      # output layer\n",
        "      output = Dense(1, activation='sigmoid', kernel_regularizer= l2(hp.Float('output layer l2_reg', min_value=1e-5, max_value=1e-2, sampling='log')))(x)\n",
        "\n",
        "\n",
        "      # compiling\n",
        "      model = Model(inputs=[feature1, feature2], outputs=output)\n",
        "      model.compile(optimizer=keras.optimizers.Adam(\n",
        "          learning_rate=hp.Float('lr', 1e-4, 1e-2, sampling='LOG'), ema_momentum=hp.Float('momentum', 1e-4, 1e-2, sampling='LOG')),\n",
        "          loss=BinaryCrossentropy(),\n",
        "          metrics=[AUC()])\n",
        "      return model\n",
        "\n",
        "  def fit(self, hp, model, x, y, val_split = None, n_bins = None, window_size = None, **kwargs):\n",
        "\n",
        "    if window_size is None:\n",
        "      window_size = hp.get('window')\n",
        "    if n_bins is None:\n",
        "      n_bins= hp.get('n_bins')\n",
        "\n",
        "    S = Shrinker(window_size)\n",
        "    O = OutlierEliminator()\n",
        "    SAX_trans = SAX_Transformer(n_bins)\n",
        "\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size= val_split, shuffle= False)\n",
        "\n",
        "\n",
        "    x_train, y_train = S.fit_transform(x_train, y_train)\n",
        "\n",
        "    O.fit(x_train)\n",
        "    x_train, _ = O.transform(x_train, y_train)\n",
        "\n",
        "    SAX_trans.fit(x_train)\n",
        "    x_train, _ = SAX_trans.transform(x_train, y_train)\n",
        "\n",
        "\n",
        "    x_val, y_val = S.transform(x_val, y_val)\n",
        "    x_val, _ = O.transform(x_val, y_val)\n",
        "    x_val, _ = SAX_trans.transform(x_val, y_val)\n",
        "\n",
        "\n",
        "    input_vars_train = [x_train[:, :, 0: n_bins], x_train[:, :, n_bins:n_bins*2]]\n",
        "    input_vars_val = [x_val[:, :, 0: n_bins], x_val[:, :, n_bins:n_bins*2]]\n",
        "\n",
        "\n",
        "    return model.fit(x = input_vars_train, y = y_train, validation_data=(input_vars_val, y_val), **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qtvq2zqjEMEA",
        "outputId": "3868e169-31f7-4307-ed8f-7577de93d2e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 16 Complete [00h 01m 24s]\n",
            "val_loss: 0.3785426914691925\n",
            "\n",
            "Best val_loss So Far: 0.36312299966812134\n",
            "Total elapsed time: 00h 17m 15s\n",
            "\n",
            "Search: Running Trial #17\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "100               |110               |window\n",
            "7                 |9                 |n_bins\n",
            "3                 |2                 |cnn filters feature 1\n",
            "3                 |1                 |cnn filters feature 2\n",
            "3                 |3                 |kernel_size feature 1\n",
            "3                 |5                 |kernel_size feature 2\n",
            "4                 |5                 |pool_size feature 1\n",
            "3                 |3                 |pool_size feature 2\n",
            "True              |False             |cnn\n",
            "3                 |3                 |num_lstm_layers\n",
            "20                |60                |1 lstm layer feature 1 units\n",
            "0.0042735         |0.012788          |1 lstm layer feature 1 l2_reg\n",
            "40                |20                |1 lstm layer feature 2 units\n",
            "0.00068457        |0.0035885         |1 lstm layer feature 2 l2_reg\n",
            "False             |True              |1 layer lstm dropout\n",
            "3                 |3                 |dim_reduction_layer__units\n",
            "0.0052982         |2.7322e-06        |dense dim reduction l2_reg\n",
            "2                 |3                 |num_hidden_layers\n",
            "44                |4                 |1 dense layer units\n",
            "3.3535e-05        |0.063665          |1 dense layer l2_reg\n",
            "0                 |0.4               |1 dropout_rate\n",
            "0.0058353         |0.00052207        |output layer l2_reg\n",
            "0.00042981        |0.00012279        |lr\n",
            "0.0070834         |0.007587          |momentum\n",
            "0.5               |0.3               |1 lstm layer feature 1 dropout_rate\n",
            "0.1               |0.3               |1 lstm layer feature 2 dropout_rate\n",
            "25                |25                |2 lstm layer feature 1 units\n",
            "0.011734          |0.00011538        |2 lstm layer feature 1 l2_reg\n",
            "25                |35                |2 lstm layer feature 2 units\n",
            "0.0018371         |0.00026339        |2 lstm layer feature 2 l2_reg\n",
            "False             |True              |2 layer lstm dropout\n",
            "50                |40                |3 lstm layer feature 1 units\n",
            "1.386e-06         |2.3006e-06        |3 lstm layer feature 1 l2_reg\n",
            "55                |15                |3 lstm layer feature 2 units\n",
            "2.3297e-06        |1.0175e-06        |3 lstm layer feature 2 l2_reg\n",
            "False             |True              |3 layer lstm dropout\n",
            "0.0089081         |0.00038602        |3 dense layer l2_reg\n",
            "36                |40                |2 dense layer units\n",
            "0.4               |0.4               |2 dropout_rate\n",
            "0.00021034        |0.00022121        |cnn feature 1 l2_reg\n",
            "True              |True              |avg_pool\n",
            "0.5               |0.1               |3 lstm layer feature 1 dropout_rate\n",
            "0.3               |0.4               |3 lstm layer feature 2 dropout_rate\n",
            "60                |30                |4 lstm layer feature 1 units\n",
            "2.2002e-05        |2.2674e-06        |4 lstm layer feature 1 l2_reg\n",
            "5                 |55                |4 lstm layer feature 2 units\n",
            "0.00070052        |0.0034109         |4 lstm layer feature 2 l2_reg\n",
            "True              |True              |4 layer lstm dropout\n",
            "10                |65                |5 lstm layer feature 1 units\n",
            "7.5838e-05        |1.0368e-05        |5 lstm layer feature 1 l2_reg\n",
            "30                |40                |5 lstm layer feature 2 units\n",
            "0.0011763         |0.00027472        |5 lstm layer feature 2 l2_reg\n",
            "False             |True              |5 layer lstm dropout\n",
            "4.3258e-06        |0.0026379         |5 dense layer l2_reg\n",
            "36                |28                |3 dense layer units\n",
            "0.1               |0                 |3 dropout_rate\n",
            "0.3               |0.1               |2 lstm layer feature 1 dropout_rate\n",
            "0.2               |0.1               |2 lstm layer feature 2 dropout_rate\n",
            "65                |15                |6 lstm layer feature 1 units\n",
            "0.034894          |0.0069894         |6 lstm layer feature 1 l2_reg\n",
            "35                |35                |6 lstm layer feature 2 units\n",
            "5.5387e-06        |0.00087864        |6 lstm layer feature 2 l2_reg\n",
            "False             |False             |6 layer lstm dropout\n",
            "5                 |10                |7 lstm layer feature 1 units\n",
            "0.0017356         |1.1998e-06        |7 lstm layer feature 1 l2_reg\n",
            "40                |15                |7 lstm layer feature 2 units\n",
            "2.4878e-06        |0.018192          |7 lstm layer feature 2 l2_reg\n",
            "True              |True              |7 layer lstm dropout\n",
            "20                |10                |8 lstm layer feature 1 units\n",
            "0.00049059        |0.00085668        |8 lstm layer feature 1 l2_reg\n",
            "15                |20                |8 lstm layer feature 2 units\n",
            "0.0074087         |0.00024781        |8 lstm layer feature 2 l2_reg\n",
            "True              |False             |8 layer lstm dropout\n",
            "0.00032461        |6.9429e-05        |8 dense layer l2_reg\n",
            "12                |32                |4 dense layer units\n",
            "0.3               |0.3               |4 dropout_rate\n",
            "52                |52                |5 dense layer units\n",
            "0.3               |0.1               |5 dropout_rate\n",
            "0.3               |0.1               |4 lstm layer feature 1 dropout_rate\n",
            "0.2               |0.1               |4 lstm layer feature 2 dropout_rate\n",
            "0.3               |0.1               |8 lstm layer feature 1 dropout_rate\n",
            "0.3               |0.4               |8 lstm layer feature 2 dropout_rate\n",
            "10                |5                 |9 lstm layer feature 1 units\n",
            "8.4842e-05        |2.7531e-05        |9 lstm layer feature 1 l2_reg\n",
            "10                |55                |9 lstm layer feature 2 units\n",
            "2.4374e-06        |4.8467e-06        |9 lstm layer feature 2 l2_reg\n",
            "False             |True              |9 layer lstm dropout\n",
            "65                |45                |10 lstm layer feature 1 units\n",
            "4.1205e-06        |9.7699e-05        |10 lstm layer feature 1 l2_reg\n",
            "5                 |35                |10 lstm layer feature 2 units\n",
            "0.072548          |2.3426e-06        |10 lstm layer feature 2 l2_reg\n",
            "False             |False             |10 layer lstm dropout\n",
            "2.6279e-06        |0.083458          |10 dense layer l2_reg\n",
            "0.4               |0.3               |7 lstm layer feature 1 dropout_rate\n",
            "0.3               |0.1               |7 lstm layer feature 2 dropout_rate\n",
            "0.2               |0.3               |9 lstm layer feature 1 dropout_rate\n",
            "0.2               |0.1               |9 lstm layer feature 2 dropout_rate\n",
            "0.021511          |0.00016895        |9 dense layer l2_reg\n",
            "3.8951e-06        |0.00084685        |4 dense layer l2_reg\n",
            "0.4               |0.2               |5 lstm layer feature 1 dropout_rate\n",
            "0.2               |0.3               |5 lstm layer feature 2 dropout_rate\n",
            "0.2               |0.4               |6 lstm layer feature 1 dropout_rate\n",
            "0.1               |0.5               |6 lstm layer feature 2 dropout_rate\n",
            "0.004632          |None              |2 dense layer l2_reg\n",
            "4                 |4                 |tuner/epochs\n",
            "0                 |2                 |tuner/initial_epoch\n",
            "1                 |2                 |tuner/bracket\n",
            "0                 |1                 |tuner/round\n",
            "\n",
            "Epoch 1/4\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-719c96de7d06>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtuner_cnn_lstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Light'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CO2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Occupancy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Save the build config for model loading later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-b77a2b05914c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, x, y, val_split, n_bins, window_size, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_vars_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vars_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_autograph_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Permanently allowed: %s: AutoGraph artifact'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m   \u001b[0;31m# If this is a partial, unwrap it and redo all the checks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mone_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             outputs = self.distribute_strategy.run(\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1671\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1672\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1673\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4060\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4061\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_autograph_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Permanently allowed: %s: AutoGraph artifact'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m   \u001b[0;31m# If this is a partial, unwrap it and redo all the checks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mone_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The model does not have any trainable weights.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;31m# Apply gradient updates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0;31m# Apply variable constraints after applying gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36m_backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;31m# Run udpate step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             self._backend_update_step(\n\u001b[0m\u001b[1;32m    420\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36m_backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_reduce_sum_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_tf_update_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribute_lib.get_replica_context().merge_call(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36m_distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             distribution.extended.update(\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3005\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m       return self._replica_ctx_update(\n\u001b[0m\u001b[1;32m   3008\u001b[0m           var, fn, args=args, kwargs=kwargs, group=group)\n\u001b[1;32m   3009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2884\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2886\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2888\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3476\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   3477\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 3478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3480\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3483\u001b[0m         _CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   3484\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3485\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3486\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3487\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2883\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2884\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2886\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3003\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   3004\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3005\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3007\u001b[0m       return self._replica_ctx_update(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4073\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4074\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4075\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4079\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4081\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4082\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4083\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    130\u001b[0m     ):\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py\u001b[0m in \u001b[0;36mupdate_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_velocities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_variable_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta_2_power\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta_1_power\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         self.assign_add(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/numpy.py\u001b[0m in \u001b[0;36msqrt\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   5734\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5735\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5736\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/sparse.py\u001b[0m in \u001b[0;36msparse_wrapper\u001b[0;34m(x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m             )\n\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/numpy.py\u001b[0m in \u001b[0;36msqrt\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2307\u001b[0m     )\n\u001b[1;32m   2308\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2309\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36msqrt\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m   5685\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0msame\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msparsity\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5686\u001b[0m   \"\"\"\n\u001b[0;32m-> 5687\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msqrt\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m  11941\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11942\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11943\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m  11944\u001b[0m         \"Sqrt\", x=x, name=name)\n\u001b[1;32m  11945\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    797\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m     return super()._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         compute_device)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   2675\u001b[0m     \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_NodeDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2677\u001b[0;31m     \u001b[0minput_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2678\u001b[0m     \u001b[0mcontrol_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_dependencies_for_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m     \u001b[0;31m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2675\u001b[0m     \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_NodeDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2677\u001b[0;31m     \u001b[0minput_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2678\u001b[0m     \u001b[0mcontrol_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_dependencies_for_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m     \u001b[0;31m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "tuner_cnn_lstm_model = kt.Hyperband(\n",
        "    CNN_LSTM_Model(),\n",
        "    objective=kt.Objective('val_loss', direction=\"min\"),\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    seed= 42,\n",
        "    directory='model selction',\n",
        "    project_name='cnn_lstm_light_co2_model'\n",
        ")\n",
        "\n",
        "\n",
        "tuner_cnn_lstm_model.search(x =train[['Light', 'CO2']], y = train['Occupancy'], epochs=5, val_split=0.15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKibpoquL8ng"
      },
      "source": [
        "### LSTM Model with hours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrqephWIGWee"
      },
      "outputs": [],
      "source": [
        "class Model_wHours(kt.HyperModel):\n",
        "\n",
        "  def build(self, hp):\n",
        "\n",
        "      # it defines the widows size and the number of bin for the SAX\n",
        "      window_size = hp.Int('window', 30, 120, step=10)\n",
        "      n_bins = hp.Int('n_bins', 5, 10, step=1)\n",
        "\n",
        "\n",
        "      input_shape = (window_size, n_bins)\n",
        "\n",
        "      # inputs layer\n",
        "      feature1 = Input(shape=input_shape, name=\"feature_1\")\n",
        "      feature2 = Input(shape=input_shape, name=\"feature_2\")\n",
        "      hours = Input(shape=(window_size, 1), name=\"hours\")\n",
        "\n",
        "\n",
        "      # concatenate each feature with hours\n",
        "      feature1_with_hours = Concatenate()([feature1, hours])\n",
        "      feature2_with_hours = Concatenate()([feature2, hours])\n",
        "\n",
        "\n",
        "\n",
        "      # LSTM layers\n",
        "      lstm_first = True\n",
        "      n_lstm_layers = hp.Int('num_lstm_layers', 1, 10)\n",
        "      for lstm_layer in range(n_lstm_layers):\n",
        "\n",
        "        # it checks if it is on the last layer of LSTM\n",
        "        if lstm_layer + 1 == n_lstm_layers:\n",
        "          flag_sequence = False\n",
        "        else:\n",
        "          flag_sequence = True\n",
        "\n",
        "\n",
        "        if lstm_first:\n",
        "          lstmFeature1 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 1 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 1 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(feature1_with_hours)\n",
        "\n",
        "          lstmFeature2 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 2 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 2 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(feature2_with_hours)\n",
        "\n",
        "\n",
        "        else:\n",
        "          lstmFeature1 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 1 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 1 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(lstmFeature1)\n",
        "\n",
        "          lstmFeature2 = LSTM(hp.Int(f'{lstm_layer + 1} lstm layer feature 2 units', 5, 65, step=5), return_sequences = flag_sequence,\n",
        "                              kernel_regularizer= l2(hp.Float(f'{lstm_layer + 1} lstm layer feature 2 l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(lstmFeature2)\n",
        "\n",
        "\n",
        "        # Dropout for each LSTM layer\n",
        "        if hp.Boolean(f'{lstm_layer + 1} layer lstm dropout'):\n",
        "          lstmFeature1 = Dropout(hp.Float(f'{lstm_layer + 1} lstm layer feature 1 dropout_rate', 0.1, 0.5, step=0.1))(lstmFeature1)\n",
        "          lstmFeature2 = Dropout(hp.Float(f'{lstm_layer + 1} lstm layer feature 2 dropout_rate', 0.1, 0.5, step=0.1))(lstmFeature2)\n",
        "\n",
        "\n",
        "      # merging the two LSTM layers\n",
        "      x = Concatenate()([lstmFeature1, lstmFeature2])\n",
        "      x = Dense(hp.Int('dim_reduction_layer__units', 1, x.shape[1]//2, step=1), activation='relu',\n",
        "                kernel_regularizer = l2(hp.Float('dense dim reduction l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(x)  # it helps to reduce the dimensionality\n",
        "\n",
        "\n",
        "      # perceptron layers\n",
        "      num_hidden_layers = hp.Int('num_hidden_layers', 1, 5)\n",
        "      for layer in range(num_hidden_layers):\n",
        "\n",
        "          x = Dense(hp.Int(f'{layer + 1} dense layer units', 4, 64, step=4), activation='relu',\n",
        "                     kernel_regularizer = l2(hp.Float(f'{lstm_layer + 1} dense layer l2_reg', min_value=1e-6, max_value=1e-1, sampling='log')))(x)\n",
        "          x = Dropout(hp.Float(f'{layer + 1} dropout_rate', 0, 0.5, step=0.1))(x)\n",
        "\n",
        "      # output layer\n",
        "      output = Dense(1, activation='sigmoid', kernel_regularizer= l2(hp.Float('output layer l2_reg', min_value=1e-5, max_value=1e-2, sampling='log')))(x)\n",
        "\n",
        "\n",
        "      # compiling\n",
        "      model = Model(inputs=[feature1, feature2, hours], outputs=output)\n",
        "      model.compile(optimizer=keras.optimizers.Adam(\n",
        "          learning_rate=hp.Float('lr', 1e-4, 1e-2, sampling='LOG'), ema_momentum=hp.Float('momentum', 1e-4, 1e-2, sampling='LOG')),\n",
        "          loss=BinaryCrossentropy(),\n",
        "          metrics=[AUC()])\n",
        "      return model\n",
        "\n",
        "\n",
        "                                  # as perc float    # as tuple\n",
        "  def fit(self, hp, model, x, y, val_split = None, n_bins = None, window_size = None, **kwargs):\n",
        "\n",
        "    if window_size is None:\n",
        "      window_size = hp.get('window')\n",
        "    if n_bins is None:\n",
        "      n_bins= hp.get('n_bins')\n",
        "\n",
        "    S = Shrinker(window_size)\n",
        "    O = OutlierEliminator(ignored_indices = [2])\n",
        "    SAX_trans = SAX_Transformer(n_bins, ignored_indices = [2])\n",
        "\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size= val_split, shuffle= False)\n",
        "\n",
        "\n",
        "    x_train, y_train = S.fit_transform(x_train, y_train)\n",
        "\n",
        "    O.fit(x_train)\n",
        "    x_train, _ = O.transform(x_train, y_train)\n",
        "\n",
        "    SAX_trans.fit(x_train)\n",
        "    x_train, _ = SAX_trans.transform(x_train, y_train)\n",
        "\n",
        "\n",
        "    x_val, y_val = S.transform(x_val, y_val)\n",
        "    x_val, _ = O.transform(x_val, y_val)\n",
        "    x_val, _ = SAX_trans.transform(x_val, y_val)\n",
        "\n",
        "\n",
        "    input_vars_train = [x_train[:, :, 0: n_bins], x_train[:, :, n_bins:n_bins*2], x_train[:, :, n_bins*2]]\n",
        "    input_vars_val = [x_val[:, :, 0: n_bins], x_val[:, :, n_bins:n_bins*2], x_val[:, :, n_bins*2]]\n",
        "\n",
        "\n",
        "    return model.fit(x = input_vars_train, y = y_train, validation_data=(input_vars_val, y_val), **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HRTmLgRAJOOo",
        "outputId": "aab6ca46-fef4-46c3-9e16-6f57aeaa174a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 02m 12s]\n",
            "val_loss: 0.374039888381958\n",
            "\n",
            "Best val_loss So Far: 0.374039888381958\n",
            "Total elapsed time: 00h 04m 55s\n",
            "\n",
            "Search: Running Trial #4\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "120               |110               |window\n",
            "6                 |9                 |n_bins\n",
            "6                 |3                 |num_lstm_layers\n",
            "35                |10                |1 lstm layer feature 1 units\n",
            "0.0011434         |2.4999e-05        |1 lstm layer feature 1 l2_reg\n",
            "45                |65                |1 lstm layer feature 2 units\n",
            "9.3886e-05        |0.013673          |1 lstm layer feature 2 l2_reg\n",
            "False             |False             |1 layer lstm dropout\n",
            "3                 |1                 |dim_reduction_layer__units\n",
            "1.8558e-06        |1.6021e-05        |dense dim reduction l2_reg\n",
            "3                 |5                 |num_hidden_layers\n",
            "8                 |56                |1 dense layer units\n",
            "1.2137e-06        |1.5868e-05        |1 dense layer l2_reg\n",
            "0                 |0.3               |1 dropout_rate\n",
            "4.8583e-05        |0.0060109         |output layer l2_reg\n",
            "0.0030983         |0.0010712         |lr\n",
            "0.00032438        |0.00014949        |momentum\n",
            "55                |35                |2 lstm layer feature 1 units\n",
            "0.0080871         |1.8273e-06        |2 lstm layer feature 1 l2_reg\n",
            "25                |65                |2 lstm layer feature 2 units\n",
            "4.1748e-05        |0.031644          |2 lstm layer feature 2 l2_reg\n",
            "True              |True              |2 layer lstm dropout\n",
            "30                |5                 |3 lstm layer feature 1 units\n",
            "1.4077e-06        |0.050138          |3 lstm layer feature 1 l2_reg\n",
            "65                |40                |3 lstm layer feature 2 units\n",
            "0.055349          |0.00039709        |3 lstm layer feature 2 l2_reg\n",
            "True              |False             |3 layer lstm dropout\n",
            "10                |30                |4 lstm layer feature 1 units\n",
            "0.00080299        |0.00029455        |4 lstm layer feature 1 l2_reg\n",
            "30                |35                |4 lstm layer feature 2 units\n",
            "3.4651e-06        |0.0022268         |4 lstm layer feature 2 l2_reg\n",
            "False             |True              |4 layer lstm dropout\n",
            "60                |5                 |5 lstm layer feature 1 units\n",
            "5.1463e-05        |9.2722e-06        |5 lstm layer feature 1 l2_reg\n",
            "25                |5                 |5 lstm layer feature 2 units\n",
            "0.0088781         |0.0072103         |5 lstm layer feature 2 l2_reg\n",
            "False             |True              |5 layer lstm dropout\n",
            "2.3601e-06        |0.00081836        |5 dense layer l2_reg\n",
            "52                |60                |2 dense layer units\n",
            "0.1               |0.2               |2 dropout_rate\n",
            "36                |56                |3 dense layer units\n",
            "0.4               |0                 |3 dropout_rate\n",
            "40                |40                |4 dense layer units\n",
            "0.3               |0.2               |4 dropout_rate\n",
            "36                |8                 |5 dense layer units\n",
            "0                 |0.4               |5 dropout_rate\n",
            "0.2               |0.4               |5 lstm layer feature 1 dropout_rate\n",
            "0.1               |0.5               |5 lstm layer feature 2 dropout_rate\n",
            "0.1               |0.1               |2 lstm layer feature 1 dropout_rate\n",
            "0.4               |0.1               |2 lstm layer feature 2 dropout_rate\n",
            "2.8431e-06        |1e-06             |3 dense layer l2_reg\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "2                 |2                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "Epoch 1/2\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 52ms/step - auc: 0.7617 - loss: 0.4069 - val_auc: 0.7939 - val_loss: 0.3620\n",
            "Epoch 2/2\n",
            "\u001b[1m287/329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - auc: 0.9053 - loss: 0.2487"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e3dbd63785fc>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtuner_cnn_lstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Light'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CO2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hour'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Occupancy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Save the build config for model loading later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-1ffddf9638cf>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, x, y, val_split, n_bins, window_size, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_vars_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vars_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "tuner_lstm_hour_model = kt.Hyperband(\n",
        "    Model_wHours(),\n",
        "    objective=kt.Objective('val_loss', direction=\"min\"),\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    seed= 42,\n",
        "    directory='model selction',\n",
        "    project_name='lstm_light_co2_hour_hb'\n",
        ")\n",
        "\n",
        "\n",
        "tuner_lstm_hour_model.search(x =train[['Light', 'CO2', 'hour']], y = train['Occupancy'], epochs=5, val_split=0.15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vASw_YcX0Uv"
      },
      "source": [
        "# Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfcrHKdwX2li",
        "outputId": "a0fec7bb-59ff-4066-8e21-2610c0e2a05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 fold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 84ms/step - auc: 0.9373 - loss: 0.2136\n",
            "Epoch 2/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 79ms/step - auc: 0.9706 - loss: 0.1564\n",
            "Epoch 3/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 79ms/step - auc: 0.9803 - loss: 0.1208\n",
            "Epoch 4/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 80ms/step - auc: 0.9877 - loss: 0.1023\n",
            "Epoch 5/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - auc: 0.9873 - loss: 0.1012\n",
            "Epoch 6/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 75ms/step - auc: 0.9852 - loss: 0.1126\n",
            "Epoch 7/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 83ms/step - auc: 0.9685 - loss: 0.1653\n",
            "Epoch 8/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 90ms/step - auc: 0.9814 - loss: 0.1351\n",
            "Epoch 9/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 82ms/step - auc: 0.9878 - loss: 0.1086\n",
            "Epoch 10/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 84ms/step - auc: 0.9907 - loss: 0.0901\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step\n",
            "2 fold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 80ms/step - auc: 0.9453 - loss: 0.2068\n",
            "Epoch 2/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 78ms/step - auc: 0.9751 - loss: 0.1459\n",
            "Epoch 3/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 74ms/step - auc: 0.9644 - loss: 0.1664\n",
            "Epoch 4/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 78ms/step - auc: 0.9712 - loss: 0.1526\n",
            "Epoch 5/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - auc: 0.9753 - loss: 0.1448\n",
            "Epoch 6/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - auc: 0.9876 - loss: 0.1188\n",
            "Epoch 7/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 83ms/step - auc: 0.9827 - loss: 0.1306\n",
            "Epoch 8/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 73ms/step - auc: 0.9928 - loss: 0.0932\n",
            "Epoch 9/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 77ms/step - auc: 0.9934 - loss: 0.0853\n",
            "Epoch 10/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 79ms/step - auc: 0.9938 - loss: 0.0857\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step\n",
            "3 fold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 81ms/step - auc: 0.8122 - loss: 0.4203\n",
            "Epoch 2/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 80ms/step - auc: 0.9745 - loss: 0.1415\n",
            "Epoch 3/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 84ms/step - auc: 0.9831 - loss: 0.1264\n",
            "Epoch 4/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 76ms/step - auc: 0.9618 - loss: 0.1742\n",
            "Epoch 5/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 83ms/step - auc: 0.9733 - loss: 0.1429\n",
            "Epoch 6/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 87ms/step - auc: 0.9875 - loss: 0.1052\n",
            "Epoch 7/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 80ms/step - auc: 0.9887 - loss: 0.1038\n",
            "Epoch 8/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 79ms/step - auc: 0.9913 - loss: 0.0959\n",
            "Epoch 9/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - auc: 0.9819 - loss: 0.1448\n",
            "Epoch 10/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - auc: 0.9808 - loss: 0.1444\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step\n",
            "4 fold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 82ms/step - auc: 0.9541 - loss: 0.1807\n",
            "Epoch 2/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 79ms/step - auc: 0.9858 - loss: 0.1000\n",
            "Epoch 3/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 81ms/step - auc: 0.9883 - loss: 0.0979\n",
            "Epoch 4/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 74ms/step - auc: 0.9896 - loss: 0.0831\n",
            "Epoch 5/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 87ms/step - auc: 0.9898 - loss: 0.0906\n",
            "Epoch 6/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 79ms/step - auc: 0.9921 - loss: 0.0806\n",
            "Epoch 7/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - auc: 0.9940 - loss: 0.0692\n",
            "Epoch 8/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 82ms/step - auc: 0.9958 - loss: 0.0635\n",
            "Epoch 9/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 73ms/step - auc: 0.9946 - loss: 0.0695\n",
            "Epoch 10/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 73ms/step - auc: 0.9960 - loss: 0.0649\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 fold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - auc: 0.9441 - loss: 0.2158\n",
            "Epoch 2/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - auc: 0.9672 - loss: 0.1555\n",
            "Epoch 3/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 79ms/step - auc: 0.9714 - loss: 0.1512\n",
            "Epoch 4/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 79ms/step - auc: 0.9673 - loss: 0.1622\n",
            "Epoch 5/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 78ms/step - auc: 0.9692 - loss: 0.1569\n",
            "Epoch 6/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 74ms/step - auc: 0.9703 - loss: 0.1538\n",
            "Epoch 7/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 74ms/step - auc: 0.9818 - loss: 0.1235\n",
            "Epoch 8/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 76ms/step - auc: 0.9855 - loss: 0.1154\n",
            "Epoch 9/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 86ms/step - auc: 0.9929 - loss: 0.0886\n",
            "Epoch 10/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 81ms/step - auc: 0.9944 - loss: 0.0816\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step\n",
            "6 fold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 79ms/step - auc: 0.9535 - loss: 0.1886\n",
            "Epoch 2/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 79ms/step - auc: 0.9797 - loss: 0.1171\n",
            "Epoch 3/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 84ms/step - auc: 0.9802 - loss: 0.1264\n",
            "Epoch 4/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 73ms/step - auc: 0.9871 - loss: 0.1076\n",
            "Epoch 5/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 78ms/step - auc: 0.9923 - loss: 0.0843\n",
            "Epoch 6/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 85ms/step - auc: 0.9958 - loss: 0.0655\n",
            "Epoch 7/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 84ms/step - auc: 0.9939 - loss: 0.0687\n",
            "Epoch 8/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 78ms/step - auc: 0.9954 - loss: 0.0610\n",
            "Epoch 9/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 83ms/step - auc: 0.9948 - loss: 0.0644\n",
            "Epoch 10/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 84ms/step - auc: 0.9937 - loss: 0.0820\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step\n",
            "7 fold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - auc: 0.9488 - loss: 0.2038\n",
            "Epoch 2/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - auc: 0.9624 - loss: 0.1902\n",
            "Epoch 3/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 85ms/step - auc: 0.9725 - loss: 0.1633\n",
            "Epoch 4/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 83ms/step - auc: 0.9749 - loss: 0.1423\n",
            "Epoch 5/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 75ms/step - auc: 0.9806 - loss: 0.1310\n",
            "Epoch 6/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 78ms/step - auc: 0.9733 - loss: 0.1569\n",
            "Epoch 7/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 81ms/step - auc: 0.9812 - loss: 0.1186\n",
            "Epoch 8/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 80ms/step - auc: 0.9878 - loss: 0.1105\n",
            "Epoch 9/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 78ms/step - auc: 0.9861 - loss: 0.1181\n",
            "Epoch 10/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 73ms/step - auc: 0.9914 - loss: 0.0980\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step\n",
            "8 fold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 93ms/step - auc: 0.9421 - loss: 0.2104\n",
            "Epoch 2/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 84ms/step - auc: 0.9697 - loss: 0.1482\n",
            "Epoch 3/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 76ms/step - auc: 0.9660 - loss: 0.1819\n",
            "Epoch 4/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 81ms/step - auc: 0.9673 - loss: 0.1452\n",
            "Epoch 5/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 84ms/step - auc: 0.9635 - loss: 0.1562\n",
            "Epoch 6/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 79ms/step - auc: 0.9635 - loss: 0.1494\n",
            "Epoch 7/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - auc: 0.9693 - loss: 0.1390\n",
            "Epoch 8/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 76ms/step - auc: 0.9697 - loss: 0.1390\n",
            "Epoch 9/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 78ms/step - auc: 0.9663 - loss: 0.1430\n",
            "Epoch 10/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 79ms/step - auc: 0.9630 - loss: 0.1624\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step\n",
            "9 fold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 79ms/step - auc: 0.9425 - loss: 0.2008\n",
            "Epoch 2/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 77ms/step - auc: 0.9753 - loss: 0.1372\n",
            "Epoch 3/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 73ms/step - auc: 0.9724 - loss: 0.1481\n",
            "Epoch 4/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 80ms/step - auc: 0.9784 - loss: 0.1305\n",
            "Epoch 5/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 85ms/step - auc: 0.9752 - loss: 0.1313\n",
            "Epoch 6/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 80ms/step - auc: 0.9761 - loss: 0.1286\n",
            "Epoch 7/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 82ms/step - auc: 0.9830 - loss: 0.1189\n",
            "Epoch 8/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - auc: 0.9944 - loss: 0.0781\n",
            "Epoch 9/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 77ms/step - auc: 0.9845 - loss: 0.1219\n",
            "Epoch 10/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 80ms/step - auc: 0.9877 - loss: 0.1077\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step\n",
            "10 fold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 82ms/step - auc: 0.9454 - loss: 0.2140\n",
            "Epoch 2/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - auc: 0.9812 - loss: 0.1250\n",
            "Epoch 3/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 83ms/step - auc: 0.9867 - loss: 0.1064\n",
            "Epoch 4/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 75ms/step - auc: 0.9847 - loss: 0.1168\n",
            "Epoch 5/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 78ms/step - auc: 0.9752 - loss: 0.1485\n",
            "Epoch 6/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 81ms/step - auc: 0.9871 - loss: 0.1170\n",
            "Epoch 7/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - auc: 0.9921 - loss: 0.0930\n",
            "Epoch 8/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - auc: 0.9818 - loss: 0.1416\n",
            "Epoch 9/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 76ms/step - auc: 0.9928 - loss: 0.0991\n",
            "Epoch 10/10\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 91ms/step - auc: 0.9947 - loss: 0.0772\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step\n",
            "Accuracy: 0.9430485762144054\n",
            "F1-score for class 0: 0.9592326139088729\n",
            "F1-score for class 1: 0.9055555555555556\n",
            "Precision for class 0: 0.9852216748768473\n",
            "Precision for class 1: 0.8534031413612565\n",
            "Recall for class 0: 0.9345794392523364\n",
            "Recall for class 1: 0.9644970414201184\n",
            "[[800  56]\n",
            " [ 12 326]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "S = Shrinker(window_size)\n",
        "O = OutlierEliminator(ignored_indices = [2,3])\n",
        "SAX_trans = SAX_Transformer(n_bins, ignored_indices = [2,3])\n",
        "\n",
        "data = train[['Light', 'CO2', 'hour','Occupancy']].copy()\n",
        "n_fold = 10\n",
        "reports = list()\n",
        "\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(KFold(n_splits=n_fold).split(data)):\n",
        "  print(f'{i+1} fold')\n",
        "\n",
        "\n",
        "  train = data.iloc[train_index]\n",
        "  validation = data.iloc[val_index]\n",
        "\n",
        "\n",
        "\n",
        "  x_train, y_train = S.fit_transform(train[['Light', 'CO2', 'hour']], train['Occupancy'])\n",
        "  x_val, y_val = S.transform(validation[['Light', 'CO2', 'hour']], validation['Occupancy'])\n",
        "  x_train = S.get_logRatio(x_train, 1,0)\n",
        "  x_val = S.get_logRatio(x_val, 1,0)\n",
        "\n",
        "  x_train, _ = O.fit_transform(x_train, y_train)\n",
        "  x_val, _ = O.transform(x_val, y_val)\n",
        "\n",
        "  x_train, _ = SAX_trans.fit_transform(x_train, y_train)\n",
        "  x_val, _ = SAX_trans.transform(x_val, y_val)\n",
        "\n",
        "  input_vars_train = [x_train[:, :, 0: n_bins], x_train[:, :, n_bins:n_bins*2], x_train[:, :, n_bins*2], x_train[:, :, n_bins*2 +1]]\n",
        "  input_vars_val = [x_val[:, :, 0: n_bins], x_val[:, :, n_bins:n_bins*2], x_val[:, :, n_bins*2], x_val[:, :, n_bins*2 +1]]\n",
        "\n",
        "\n",
        "  best_model = tuner_best_model.get_best_models(num_models=1)[0]    # in this way the model resets itself through each fold\n",
        "  best_model.fit(input_vars_train ,y_train, epochs = 10)\n",
        "  y_pred = best_model.predict(input_vars_val)\n",
        "  y_pred = np.where(y_pred > 0.5, 1,0).astype(int)\n",
        "\n",
        "  reports.append(Report(y_val, y_pred))\n",
        "\n",
        "\n",
        "reports[0].show_report()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDICsUbgL8E6",
        "outputId": "2c0b361f-9bb2-4522-992d-dfb1739b1599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Accuracy: 0.9430485762144054\n",
            "F1-score for class 0: 0.9592326139088729\n",
            "F1-score for class 1: 0.9055555555555556\n",
            "Precision for class 0: 0.9852216748768473\n",
            "Precision for class 1: 0.8534031413612565\n",
            "Recall for class 0: 0.9345794392523364\n",
            "Recall for class 1: 0.9644970414201184\n",
            "[[800  56]\n",
            " [ 12 326]]\n",
            "\n",
            "Fold 2\n",
            "Accuracy: 0.990787269681742\n",
            "F1-score for class 0: 0.9933049300060864\n",
            "F1-score for class 1: 0.9852348993288591\n",
            "Precision for class 0: 1.0\n",
            "Precision for class 1: 0.9708994708994709\n",
            "Recall for class 0: 0.9866989117291415\n",
            "Recall for class 1: 1.0\n",
            "[[816  11]\n",
            " [  0 367]]\n",
            "\n",
            "Fold 3\n",
            "Accuracy: 0.9932998324958124\n",
            "F1-score for class 0: 0.9955056179775281\n",
            "F1-score for class 1: 0.9868421052631579\n",
            "Precision for class 0: 0.9977477477477478\n",
            "Precision for class 1: 0.9803921568627451\n",
            "Recall for class 0: 0.9932735426008968\n",
            "Recall for class 1: 0.9933774834437086\n",
            "[[886   6]\n",
            " [  2 300]]\n",
            "\n",
            "Fold 4\n",
            "Accuracy: 0.8542713567839196\n",
            "F1-score for class 0: 0.9214092140921409\n",
            "F1-score for class 1: 0.0\n",
            "Precision for class 0: 1.0\n",
            "Precision for class 1: 0.0\n",
            "Recall for class 0: 0.8542713567839196\n",
            "Recall for class 1: 0.0\n",
            "[[1020  174]\n",
            " [   0    0]]\n",
            "\n",
            "Fold 5\n",
            "Accuracy: 0.9731993299832495\n",
            "F1-score for class 0: 0.9864176570458404\n",
            "F1-score for class 1: 0.0\n",
            "Precision for class 0: 1.0\n",
            "Precision for class 1: 0.0\n",
            "Recall for class 0: 0.9731993299832495\n",
            "Recall for class 1: 0.0\n",
            "[[1162   32]\n",
            " [   0    0]]\n",
            "\n",
            "Fold 6\n",
            "Accuracy: 0.7294807370184254\n",
            "F1-score for class 0: 0.8029286150091519\n",
            "F1-score for class 1: 0.5687583444592791\n",
            "Precision for class 0: 0.6721144024514811\n",
            "Precision for class 1: 0.9906976744186047\n",
            "Recall for class 0: 0.996969696969697\n",
            "Recall for class 1: 0.398876404494382\n",
            "[[658   2]\n",
            " [321 213]]\n",
            "\n",
            "Fold 7\n",
            "Accuracy: 0.9840871021775545\n",
            "F1-score for class 0: 0.9898123324396783\n",
            "F1-score for class 1: 0.9636711281070746\n",
            "Precision for class 0: 0.9829605963791267\n",
            "Precision for class 1: 0.9882352941176471\n",
            "Recall for class 0: 0.9967602591792657\n",
            "Recall for class 1: 0.9402985074626866\n",
            "[[923   3]\n",
            " [ 16 252]]\n",
            "\n",
            "Fold 8\n",
            "Accuracy: 0.8088851634534786\n",
            "F1-score for class 0: 0.8692660550458715\n",
            "F1-score for class 1: 0.6448598130841121\n",
            "Precision for class 0: 0.9534591194968554\n",
            "Precision for class 1: 0.5201005025125628\n",
            "Recall for class 0: 0.7987355110642782\n",
            "Recall for class 1: 0.8483606557377049\n",
            "[[758 191]\n",
            " [ 37 207]]\n",
            "\n",
            "Fold 9\n",
            "Accuracy: 0.9253981559094719\n",
            "F1-score for class 0: 0.9390828199863107\n",
            "F1-score for class 1: 0.9037837837837838\n",
            "Precision for class 0: 0.9002624671916011\n",
            "Precision for class 1: 0.9698375870069605\n",
            "Recall for class 0: 0.9814020028612304\n",
            "Recall for class 1: 0.8461538461538461\n",
            "[[686  13]\n",
            " [ 76 418]]\n",
            "\n",
            "Fold 10\n",
            "Accuracy: 0.9857502095557418\n",
            "F1-score for class 0: 0.9928239763613339\n",
            "F1-score for class 1: 0.0\n",
            "Precision for class 0: 1.0\n",
            "Precision for class 1: 0.0\n",
            "Recall for class 0: 0.9857502095557418\n",
            "Recall for class 1: 0.0\n",
            "[[1176   17]\n",
            " [   0    0]]\n",
            "\n",
            "average metrics: \n",
            "\n",
            "Average accuracy: 0.9188207733273801\n",
            "Average F1-score for class 0: 0.9449783831872814\n",
            "Average F1-score for class 1: 0.5958705629581822\n",
            "Average Precision for class 0: 0.9491766008143661\n",
            "Average Precision for class 1: 0.6273565827179247\n",
            "Average Recall for class 0: 0.9501640259979757\n",
            "Average Recall for class 1: 0.5991563938712445\n"
          ]
        }
      ],
      "source": [
        "avg_acc = 0\n",
        "avg_f1_0 = 0\n",
        "avg_f1_1 = 0\n",
        "avg_precision_0 = 0\n",
        "avg_precision_1 = 0\n",
        "avg_recall_0 = 0\n",
        "avg_recall_1 = 0\n",
        "\n",
        "for fold, report in enumerate(reports):\n",
        "  print(f'Fold {fold+1}')\n",
        "\n",
        "  avg_acc += report.get_accuracy()\n",
        "  avg_f1_0 += report.get_f1_class_0()\n",
        "  avg_f1_1 += report.get_f1_class_1()\n",
        "  avg_precision_0 += report.get_precision_0()\n",
        "  avg_precision_1 += report.get_precision_1()\n",
        "  avg_recall_0 += report.get_recall_0()\n",
        "  avg_recall_1 += report.get_recall_1()\n",
        "\n",
        "  report.show_report()\n",
        "  print()\n",
        "\n",
        "print('average metrics: \\n')\n",
        "print(f'Average accuracy: {avg_acc/n_fold}')\n",
        "print(f'Average F1-score for class 0: {avg_f1_0/n_fold}')\n",
        "print(f'Average F1-score for class 1: {avg_f1_1/n_fold}')\n",
        "print(f'Average Precision for class 0: {avg_precision_0/n_fold}')\n",
        "print(f'Average Precision for class 1: {avg_precision_1/n_fold}')\n",
        "print(f'Average Recall for class 0: {avg_recall_0/n_fold}')\n",
        "print(f'Average Recall for class 1: {avg_recall_1/n_fold}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBfQsxBVoPfc"
      },
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfeAa4YlxvEI"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKLQM5uVoSa_",
        "outputId": "59ad6065-4008-4891-e65c-4bd6149da549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "P = Preprocessing(PATH, 'training_ts.csv', 'test_ts.csv')\n",
        "train = P.get_train()\n",
        "test = P.get_test()\n",
        "\n",
        "\n",
        "# Shrinking\n",
        "S = Shrinker(window_size = window_size)\n",
        "x_train_shrinked, y_train = S.fit_transform(train[['Light', 'CO2', 'hour']], train['Occupancy'])\n",
        "x_test_shrinked, y_test = S.transform(test[['Light', 'CO2', 'hour']], test['Occupancy'])\n",
        "\n",
        "# Getting logRatio feature\n",
        "x_train_shrinked = S.get_logRatio(x_train_shrinked, 1, 0)\n",
        "x_test_shrinked = S.get_logRatio(x_test_shrinked, 1, 0)\n",
        "\n",
        "\n",
        "# Outlier elimination\n",
        "O = OutlierEliminator(ignored_indices = [2,3])\n",
        "x_train_shrinked, _ = O.fit_transform(x_train_shrinked)\n",
        "x_test_shrinked, _ = O.transform(x_test_shrinked)\n",
        "\n",
        "\n",
        "# SAX transformation\n",
        "SAX = SAX_Transformer(n_bins = n_bins, ignored_indices = [2,3])\n",
        "x_train_sax, _ = SAX.fit_transform(x_train_shrinked)\n",
        "x_test_sax, _ = SAX.transform(x_test_shrinked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0H5M4OGyOCg"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9zqcWEHyRQq",
        "outputId": "df28ae8a-e68b-4c0d-8093-d0c2ddc4fb70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 78ms/step - auc: 0.9480 - loss: 0.2027\n",
            "Epoch 2/10\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 78ms/step - auc: 0.9745 - loss: 0.1350\n",
            "Epoch 3/10\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 79ms/step - auc: 0.9790 - loss: 0.1257\n",
            "Epoch 4/10\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - auc: 0.9864 - loss: 0.1116\n",
            "Epoch 5/10\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - auc: 0.9902 - loss: 0.0961\n",
            "Epoch 6/10\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 84ms/step - auc: 0.9864 - loss: 0.1108\n",
            "Epoch 7/10\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - auc: 0.9895 - loss: 0.0978\n",
            "Epoch 8/10\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 79ms/step - auc: 0.9909 - loss: 0.0898\n",
            "Epoch 9/10\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 79ms/step - auc: 0.9944 - loss: 0.0697\n",
            "Epoch 10/10\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 79ms/step - auc: 0.9947 - loss: 0.0683\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e23d763f250>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "input_vars_train = [x_train_sax[:, :, 0: n_bins], x_train_sax[:, :, n_bins:n_bins*2],\n",
        "                    x_train_sax[:, :, n_bins*2], x_train_sax[:, :, n_bins*2 +1]]\n",
        "\n",
        "best_model = tuner_best_model.get_best_models(num_models=1)[0]  # model reset\n",
        "best_model.fit(input_vars_train ,y_train, epochs = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLVtt8muynio"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVQlw3Jyym2G",
        "outputId": "53736f81-90ea-46f3-f36c-9f01fe9d0dc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m166/166\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step\n"
          ]
        }
      ],
      "source": [
        "input_vars_test = [x_test_sax[:, :, 0: n_bins], x_test_sax[:, :, n_bins:n_bins*2],\n",
        "                    x_test_sax[:, :, n_bins*2], x_test_sax[:, :, n_bins*2 +1]]\n",
        "\n",
        "y_pred = best_model.predict(input_vars_test)\n",
        "y_pred = np.where(y_pred > 0.5, 1,0).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znpmnq5Oy5PV"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYwrTu9Ay7BY",
        "outputId": "26f421c8-82ee-4dd0-867c-ff1deb728b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.98474001507159\n",
            "F1-score for class 0: 0.9904492394764768\n",
            "F1-score for class 1: 0.9620608899297424\n",
            "Precision for class 0: 0.9836065573770492\n",
            "Precision for class 1: 0.9894026974951831\n",
            "Recall for class 0: 0.9973877938731893\n",
            "Recall for class 1: 0.9361896080218779\n",
            "[[4200   11]\n",
            " [  70 1027]]\n"
          ]
        }
      ],
      "source": [
        "Report(y_test, y_pred).show_report()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}